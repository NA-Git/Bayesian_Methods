{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from prophet.plot import add_changepoints_to_plot\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('tbd')\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df['feature'] = pd.read_csv('feature')\n",
    "df['display'] = pd.read.csv('display')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of importance plots if they need to be used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def imp_plots(target, predictors):\n",
    "#     \"\"\"Form three importance plots\n",
    "#\n",
    "#     :param target:'dependent' component\n",
    "#     :param predictors:'predictive' component\n",
    "#     \"\"\"\n",
    "#     target = target\n",
    "#     df_all = df_num.dropna().astype(dtype='int32')\n",
    "#     df_all = df_all[predictors + [target]]\n",
    "#     df_train, df_test = train_test_split(df_all, test_size=0.15)\n",
    "#     X_train, y_train = df_train.drop(target, axis=1), df_train[target]\n",
    "#     X_test, y_test = df_test.drop(target, axis=1), df_test[target]\n",
    "#     rf = RandomForestClassifier(n_estimators=100, n_jobs=-1,\n",
    "#                                 max_features=1.0,\n",
    "#                                 min_samples_leaf=10, oob_score=True)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#                            max_depth=None, max_features=1.0, max_leaf_nodes=None,\n",
    "#                            min_impurity_decrease=0.0, min_samples_leaf=10,\n",
    "#                            min_samples_split=2,\n",
    "#                            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "#                            oob_score=True, random_state=None, verbose=0, warm_start=False)\n",
    "#     figure, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(10, 10))\n",
    "#     imp1 = importances(rf, X_test, y_test)\n",
    "#     plot_importances(imp1, width=16, vscale=4, ax=ax1)\n",
    "#\n",
    "#     imp = pd.DataFrame()\n",
    "#     imp['Feature'] = X_train.columns\n",
    "#     imp['Importance'] = rf.feature_importances_\n",
    "#     imp = imp.sort_values('Importance', ascending=False)\n",
    "#     imp2 = imp.set_index('Feature')\n",
    "#     plot_importances(imp2, width=16, vscale=4, ax=ax2)\n",
    "#\n",
    "#     perm_importance = permutation_importance(rf, X_test, y_test)\n",
    "#     perm = pd.DataFrame()\n",
    "#     perm['Feature'] = X_test.columns\n",
    "#     perm['Importance'] = perm_importance.importances_mean\n",
    "#     perm = perm.sort_values('Importance', ascending=False)\n",
    "#     perm = perm.set_index('Feature')\n",
    "#     plot_importances(perm, width=16, vscale=4, ax=ax3)\n",
    "#     a = imp1.sort_values(by='Feature')\n",
    "#     b = imp2.sort_values(by='Feature')\n",
    "#     c = perm.sort_values(by='Feature')\n",
    "#     d = (np.abs(a) + np.abs(b) + np.abs(c)).sort_values('Importance',\n",
    "#                                                         ascending=False).mean(axis=1)\n",
    "#     plt.show()\n",
    "#     return d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Basic check on the dataframe and determination of missing values. Initially, missing values will be dropped"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Missing Values')\n",
    "print(df['y'].isnull().sum() / len(df) * 100)\n",
    "print('Zeroes')\n",
    "print((df['y'] == 0).sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To be written when data is corrected: a check on the average, variance, skew, etc. of the two ACV features to check if averaging is appropriate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a crucial section right here. The data is not reported weekly, but reported on different days in the week, often multiple times per week. Grouping the revenue by date and summing the revenue will provide the structure needed for a forecast. Similar code will have to be written for ACV Feature and ACD Display, but most likely using averages instead of sums."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['ds'] = pd.to_datetime(df['ds']) - pd.to_timedelta(7, unit='d')\n",
    "df = df.groupby([pd.Grouper(key='df', freq='W')])['y'].sum().reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will be a standard correlation map. It will be particularly interesting to see the correlation between ACV Feature and Display, and also important how strongly both are correlated to revenue."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = df.corr(method=\"spearman\").round(2)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(18, 18))\n",
    "cmap = sns.diverging_palette(250, 1, as_cmap=True)\n",
    "sns.heatmap(corr, annot=True, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "corr.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "VIF checks for multicollinearity more accurately than a correlation plot does. A VIF greater than 5 would suggest ACF Feature and Display should not be used together."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vif_df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "\n",
    "X = vif_df\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "print(vif_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is a section that should check ACV Feature and Display to see if the values are randomly dispersed or concentrated in certain locations. I would also suggest multiplying both by 100 to avoid any issues with logarithms or squre roots."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prophet modeling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = df[df['ds'] <= 'some_date']\n",
    "df_test = df[df['ds'] >= 'some_date']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section sets all the parameters for the Prophet model. Setting the growth as linear for now, but worth experimenting with. Changepoints are locations where the rate of change is potentially allowed to change.\n",
    "The yearly, weekly, and daily seasonality are set here as auto for yearly and weekly, so Prophet can detect it, and daily for false, so it doesn't detect any false readings. Seasonality mode is defined to as either additive or multiplicative for better fitting.\n",
    "The following parameters are set to avoid overfitting. Note that at the end of the notebook there is a bit that runs a check on the priors.\n",
    "Fit should be set to false to add extra regressors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m = Prophet(growth = 'linear',\n",
    "            n_changepoints = 25,\n",
    "            changepoint_range = 0.8,\n",
    "            yearly_seasonalityc= 'auto',\n",
    "            weekly_seasonality = 'auto',\n",
    "            daily_seasonality = 'False',\n",
    "            holidays = 'prophet_holidays',\n",
    "            seasonality_mode = 'additive',\n",
    "            seasonality_prior_scale = 10.0,\n",
    "            holidays_prior_scale = 10.0,\n",
    "            changepoint_prior_scale = 0.05,\n",
    "            mcmc_samples = 800,\n",
    "            interval_width = 0.20,\n",
    "            uncertainty_samples = 500,\n",
    "            # stan_backend = 'False',\n",
    "            fit = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Earlier in the code the columns of ACV Feature and Display were added. This should define them so Prophet runs its model with them included. When I did this in R, it took some tweaks to get running properly. It then fits the Prophet model with the parameters set above."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m.add_regressor('feature, display')\n",
    "m.fit(df_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This creates a dataframe the same length of the input data, but with four additional weeks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=4, freq='W')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the Prophet model, it makes it projects for the four weeks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecast = m.predict(future)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Diagnostics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig1 = m.plot(forecast)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_components_plotly(m, forecast)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = m.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig.gca(), m, forecast)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cross_validation function here uses historical data to measure forecast error. The next function prints off the different measures it uses, like RMSE, SMAPE, etc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cv = cross_validation(m, initial='700 days', period='360 days', horizon = '30 days')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_cv_p = performance_metrics(df_cv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "#     'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "# }\n",
    "#\n",
    "# # Generate all combinations of parameters\n",
    "# all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "# rmses = []  # Store the RMSEs for each params here\n",
    "#\n",
    "# # Use cross validation to evaluate all parameters\n",
    "# for params in all_params:\n",
    "#     m = Prophet(**params).fit(df)  # Fit model with given params\n",
    "#     df_cv = cross_validation(m, cutoffs=cutoffs, horizon='30 days', parallel=\"processes\")\n",
    "#     df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "#     rmses.append(df_p['rmse'].values[0])\n",
    "#\n",
    "# # Find the best parameters\n",
    "# tuning_results = pd.DataFrame(all_params)\n",
    "# tuning_results['rmse'] = rmses\n",
    "# print(tuning_results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This plots the difference between the forecast and the actuals."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(forecast['forecast'], label='Forecast')\n",
    "plt.plot(df['y'], label='Actuals')\n",
    "leg = plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similar metrics to those from the cross_validation function could be used to compare the historical error to the model error."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
