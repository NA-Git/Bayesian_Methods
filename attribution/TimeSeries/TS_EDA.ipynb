{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pandas.plotting import lag_plot\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "from pmdarima.arima import auto_arima\n",
    "from pmdarima.arima import ADFTest\n",
    "from pmdarima import acf\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, Markdown\n",
    "from IPython.display import Math\n",
    "import datetime\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ValueError)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54039 entries, 0 to 54038\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   ClientId                                      54039 non-null  int64  \n",
      " 1   Program Id                                    54039 non-null  int64  \n",
      " 2   Program Name                                  54039 non-null  object \n",
      " 3   Retailers                                     54039 non-null  object \n",
      " 4   TacticId                                      54039 non-null  int64  \n",
      " 5   Tactic                                        54039 non-null  object \n",
      " 6   CategoryId                                    54039 non-null  int64  \n",
      " 7   Tactic Category                               54039 non-null  object \n",
      " 8   VendorId                                      53135 non-null  float64\n",
      " 9   Vendor                                        54039 non-null  object \n",
      " 10  Total Impressions for Tactic                  54039 non-null  int64  \n",
      " 11  Total Tactic Spend                            54039 non-null  float64\n",
      " 12  Total Tactic Insertion Cost                   54039 non-null  float64\n",
      " 13  Total Tactic Redemption Cost                  54039 non-null  float64\n",
      " 14  Tactic Start Date                             54039 non-null  object \n",
      " 15  Tactic End Date                               54039 non-null  object \n",
      " 16  BrandId                                       54039 non-null  int64  \n",
      " 17  Brand                                         54039 non-null  object \n",
      " 18  Nielsen_Week_Year                             54039 non-null  int64  \n",
      " 19  StoreCount                                    54031 non-null  float64\n",
      " 20  RMN                                           54039 non-null  object \n",
      " 21  Weeks                                         54039 non-null  int64  \n",
      " 22  Impressions per Week                          54039 non-null  float64\n",
      " 23  Brand Share of Program Budget                 54039 non-null  float64\n",
      " 24  Brand Share of Total Tactic Spend             54039 non-null  float64\n",
      " 25  Brand Share of Tactic Insertion Cost          54039 non-null  float64\n",
      " 26  Brand Share of Tactic Redemption Cost         54039 non-null  float64\n",
      " 27  Weekly Brand Share of Total Tactic Spend      54039 non-null  float64\n",
      " 28  Weekly Brand Share of Tactic Insertion Cost   54039 non-null  float64\n",
      " 29  Weekly Brand Share of Tactic Redemption Cost  54039 non-null  float64\n",
      " 30  Total Sales                                   20515 non-null  float64\n",
      " 31  Base $                                        20515 non-null  float64\n",
      " 32  Incr $                                        20515 non-null  float64\n",
      " 33  Units                                         20515 non-null  float64\n",
      " 34  Base Units                                    20515 non-null  float64\n",
      " 35  Incr Units                                    20515 non-null  float64\n",
      " 36  Avg Unit Price                                20523 non-null  float64\n",
      " 37  Any Promo Units                               20523 non-null  float64\n",
      " 38  %ACV Distribution                             20481 non-null  float64\n",
      " 39  Any Promo %ACV                                20481 non-null  float64\n",
      " 40  Disp w/o Feat %ACV                            20481 non-null  float64\n",
      " 41  Feat & Disp %ACV                              20481 non-null  float64\n",
      " 42  Feat w/o Disp %ACV                            20481 non-null  float64\n",
      " 43  Price Decr Only %ACV                          20481 non-null  float64\n",
      " 44  Number of UPCs Selling                        20523 non-null  float64\n",
      " 45  $ Shr - Ty Subcategory                        5220 non-null   float64\n",
      " 46  Units Shr - Ty Category                       3153 non-null   float64\n",
      " 47  Units Shr - Ty Subcategory                    5220 non-null   float64\n",
      "dtypes: float64(31), int64(8), object(9)\n",
      "memory usage: 19.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/norri/Desktop/tyson_EDA.csv')\n",
    "df.describe()\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing Values\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43my\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39misnull()\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(df) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mZeroes\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m((df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39msum())\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'y'"
     ]
    }
   ],
   "source": [
    "print('Missing Values')\n",
    "print(df['y'].isnull().sum() / len(df) * 100)\n",
    "print('Zeroes')\n",
    "print((df['y'] == 0).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initially we have over half missing, as well as a few zeroes which can be problematic during forecasting. I'll drop the zeroes since they make up a small part of the dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[df.y != 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Missing Values')\n",
    "print(df['y'].isnull().sum() / len(df) * 100)\n",
    "print('Zeroes')\n",
    "print((df['y'] == 0).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With so many more duplicated y values, looking through the data it shows that for the same date the revenue is replicated several times over. Here I group by dates and take the average of the revenue to have a single value for revenue per date value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_a = df.groupby('ds').apply('y').mean().reset_index()\n",
    "print('Missing Values')\n",
    "print(df_a['y'].isnull().sum() / len(df_a) * 100)\n",
    "print('Zeroes')\n",
    "print((df_a['y'] == 0).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is something we had to do when modeling Tyson originally, but we have to drop all of the NA's, which is about 30,000 original observations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_a= df.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The date values aren't daily; they skip a day here or there, so I decided to group them into weeks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_a['date'] = pd.to_datetime(df_a['ds']) - pd.to_timedelta(7, unit='d')\n",
    "weekly = df_a.groupby([pd.Grouper(key='date', freq='W')])['y'].sum().reset_index()\n",
    "weekly = weekly.rename(columns={'y': 'revenue'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Missing Values')\n",
    "print(weekly['revenue'].isnull().sum() / len(weekly) * 100)\n",
    "print('Zeroes')\n",
    "print((weekly['revenue'] == 0).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Still seven weeks at zero, so they have to be dropped for future methods."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weekly = weekly[weekly.revenue != 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Missing Values')\n",
    "print(weekly['revenue'].isnull().sum() / len(weekly) * 100)\n",
    "print('Zeroes')\n",
    "print((weekly['revenue'] == 0).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Sales', dpi=100):\n",
    "    plt.figure(figsize=(12, 4), dpi=dpi)\n",
    "    plt.plot(x, y, color='blue')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "plot_df(weekly, weekly['date'], weekly['revenue'], title='Sales Over Time')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The plot shows massive spikes and is wildly inconsistent. It appears that from the minimum to the maximum is five orders of magnitude."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weekly['revenue'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(weekly['revenue'],\n",
    "                                order=(1, 1, 1),\n",
    "                                seasonal_order=(0, 0, 0, 0),\n",
    "                                enforce_stationarity=True,\n",
    "                                enforce_invertibility=True)\n",
    "results = mod.fit()\n",
    "results.plot_diagnostics(figsize=(12, 12))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "THe Q-Q plots show that ARIMA is fitting very poorly here. The following autocorrelation plot is not great, but not terrible. Still with the uncertainty the data is showing, it is hard to trust it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize':(10,4), 'figure.dpi':120})\n",
    "autocorrelation_plot(weekly['revenue'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'll give auto ARIMA a chance to perfect the parameters to see if it's any better."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = weekly['revenue']\n",
    "mod_auto_arima = auto_arima(train, start_p=0, d=1, start_q=0, max_p=5,\n",
    "                         max_d=5, max_q=5, start_P=0, D=1, start_Q=0,\n",
    "                         max_P=5, max_D=5, max_Q=5, m=12, seasonal=True,\n",
    "                         error_action='warn', trace=True,\n",
    "                         suppress_warnings=True, stepwise=True,\n",
    "                         random_state=13, n_fits=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = weekly['revenue'][-12:]\n",
    "test = weekly['revenue'][:12].reset_index() # missing pass sixteen weeks\n",
    "model = auto_arima(train, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "model.fit(train)\n",
    "forecast = mod_auto_arima.predict(n_periods=12)\n",
    "fcst = pd.DataFrame(columns = ['forecast', 'test'])\n",
    "fcst['forecast'] = forecast\n",
    "fcst = fcst.reset_index()\n",
    "fcst['test'] = test['revenue']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's a truly terrible forecast. The 80 preceding values had no real capability of predicting the following twelve."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(fcst['forecast'], label='Forecast')\n",
    "plt.plot(fcst['test'], label='Actuals')\n",
    "leg = plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}