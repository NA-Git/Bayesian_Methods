{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pandas.plotting import lag_plot\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "from pmdarima.arima import auto_arima\n",
    "from pmdarima.arima import ADFTest\n",
    "from pmdarima import acf\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, Markdown\n",
    "from IPython.display import Math\n",
    "import datetime\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ValueError)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('G:/My Drive/IN/Data/Data_Standard/kind_forecast_train.csv',\n",
    "                 parse_dates=['ds'])\n",
    "df_test = pd.read_csv('G:/My Drive/IN/Data/Data_Standard/kind_forecast_test.csv',\n",
    "                 parse_dates=['ds'])\n",
    "dates = pd.read_csv('G:/My Drive/IN/Data/Forecast_Comparisons/dates.csv',\n",
    "                      parse_dates=['Date'])\n",
    "df = df.rename(columns={'ds': 'week', 'y': 'sales'})\n",
    "df_test = df_test.rename(columns={'ds': 'week', 'y': 'sales'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['sales', 'week'])\n",
    "df['week'] = df['week'] = pd.to_datetime(df['week'])\n",
    "df = df.sort_values(by=['week'])\n",
    "df['sales'] = df['sales'].values\n",
    "df['index'] = df['week']\n",
    "df.set_index('index', inplace=True)\n",
    "df = df[['week','sales']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following metrics are excellent in different situations; for example, RMSE is\n",
    "excellent for comparing similar models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forecast_accuracy(forecast, Actuals):\n",
    "    mape = np.mean(np.abs(forecast - Actuals)/np.abs(Actuals))  # MAPE\n",
    "    mae = np.mean(np.abs(forecast - Actuals))    # MAE\n",
    "    mse = np.square(np.subtract(Actuals,forecast)).mean()\n",
    "    rmse = np.mean((forecast - Actuals)**2)**.5  # RMSE\n",
    "    return({'MAPE':mape, 'MSE':mse, 'MAE': mae, 'RMSE':rmse})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are three parameters of interest for an ARIMA model: d,p, and q. D refers to\n",
    "differencing each previous value to make the model stationary. P is the term used\n",
    "for how many lags can be used for prediction. Q is the order of moving average\n",
    "to improve the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Sales', dpi=100):\n",
    "    plt.figure(figsize=(12, 4), dpi=dpi)\n",
    "    plt.plot(x, y, color='blue')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "plot_df(df, df['week'], df['sales'], title='Sales Over Time')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An increasing trend is clearly visible, though the sesaonality is not\n",
    "quite as obvious, so we will test for it later."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Augmented Dickey-Fuller Test checks for the important\n",
    "condition of stationarity. This test has failed, meaning we have to\n",
    "correct for non-stationarity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adf_test = ADFTest(alpha = .05)\n",
    "adf_test.should_diff(df['sales'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = df[:170]\n",
    "test = df[-40:]\n",
    "plt.plot(train)\n",
    "plt.plot(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Value = Base Level + Trend + Seasonality + Error - Additive Decomposition\n",
    "Value = Base Level x Trend x Seasonality x Error - Multiplicative Decompisition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multiplicative_decomposition = seasonal_decompose(df['sales'].values,\n",
    "                                                  model='multiplicative',\n",
    "                                                  period=52)\n",
    "additive_decomposition = seasonal_decompose(df['sales'].values, model='additive',\n",
    "                                            period=52)\n",
    "plt.rcParams.update({'figure.figsize': (20,14)})\n",
    "multiplicative_decomposition.plot().suptitle('Multiplicative Decomposition', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "additive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Both plots have a positive trend and display some seasonality, but the additive\n",
    "seems to have significantly better reesiduals."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "detrended = signal.detrend(df['sales'].values)\n",
    "plt.rcParams.update({'figure.figsize': (12,4)})\n",
    "plt.plot(detrended)\n",
    "plt.title('Sales Detrended', fontsize=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The plot no longer seems to be increasing in trend, hence we have detrended it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_mul = seasonal_decompose(df['sales'].values, model='multiplicative', period=52)\n",
    "deseasonalized = df['sales'].values / result_mul.seasonal\n",
    "plt.plot(deseasonalized)\n",
    "plt.title('Sales Deseasonalized', fontsize=16)\n",
    "plt.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The plot does not show a strong removal of seasonality, so move on to some testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following plot does not have any drastic spikes that suggest strong seasonality."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize':(10,4), 'figure.dpi':120})\n",
    "autocorrelation_plot(df['sales'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Autocorrelation refers to correlation of a series to its own lags. Partial autocorrelation\n",
    "refers to the correlation to a lag without reference to the lags between."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 3), dpi=100)\n",
    "plot_acf(df['sales'].tolist(), lags=52, ax=axes[0])\n",
    "plot_pacf(df['sales'].tolist(), lags=52, ax=axes[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Along with the above plots, the following metrics will quantify each degree of\n",
    "lag. Perfect autocorrelation is one, and positive means that the next value in\n",
    "the series will likely be higher."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ac1 = df['sales'].autocorr(lag=1)\n",
    "print(\"One week Lag: \", ac1)\n",
    "ac2 = df['sales'].autocorr(lag=2)\n",
    "print(\"Two week Lag: \", ac2)\n",
    "ac3 = df['sales'].autocorr(lag=3)\n",
    "print(\"Three week Lag: \", ac3)\n",
    "ac4 = df['sales'].autocorr(lag=4)\n",
    "print(\"Four Week Lag: \", ac4)\n",
    "ac5 = df['sales'].autocorr(lag=5)\n",
    "print(\"Five Week Lag: \", ac5)\n",
    "ac6 = df['sales'].autocorr(lag=6)\n",
    "print(\"Six Week Lag: \", ac6)\n",
    "ac7 = df['sales'].autocorr(lag=7)\n",
    "print(\"Seven Week Lag: \", ac7)\n",
    "ac8 = df['sales'].autocorr(lag=8)\n",
    "print(\"Eight Week Lag: \", ac8)\n",
    "ac9 = df['sales'].autocorr(lag=9)\n",
    "print(\"Nine Week Lag: \", ac9)\n",
    "ac10 = df['sales'].autocorr(lag=10)\n",
    "print(\"Ten Week Lag: \", ac10)\n",
    "ac11 = df['sales'].autocorr(lag=11)\n",
    "print(\"Eleven Week Lag: \", ac11)\n",
    "ac12 = df['sales'].autocorr(lag=12)\n",
    "print(\"Twelve Week Lag: \", ac12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These twelve weeks rather strong logs show that autocorrelation is somethng to\n",
    "be mindful in this model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update({'ytick.left' : False, 'axes.titlepad':10})\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 8), sharex=True, sharey=True, dpi=100)\n",
    "for i, ax in enumerate(axes.flatten()[:12]):\n",
    "    lag_plot(df['sales'], lag=i+1, ax=ax, c='blue')\n",
    "    ax.set_title('Lag ' + str(i+1))\n",
    "fig.suptitle('Lag Plots of Sales', y=1.05)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decreasing linear trend between lag plots demonstrates similar results to\n",
    "lag scores, suggesting some positive autocorrelation between first week"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = df['sales'][:105]\n",
    "test = df['sales'][105:]\n",
    "model = auto_arima(train, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "model.fit(train)\n",
    "forecast = model.predict(n_periods=len(test))\n",
    "forecast = pd.DataFrame(forecast,index = test.index,columns=['Prediction'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SARIMAX MODEL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(df['sales'],\n",
    "                                order=(1, 1, 1),\n",
    "                                seasonal_order=(0, 0, 0, 0),\n",
    "                                enforce_stationarity=True,\n",
    "                                enforce_invertibility=True)\n",
    "results = mod.fit()\n",
    "results.plot_diagnostics(figsize=(12, 12))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SARIMAX Diagnostics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecast = forecast.squeeze()\n",
    "forecast_accuracy(forecast, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_small = df[['week', 'sales']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = adfuller(df_small.sales.dropna())\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case, we fail the ADF test and will examine differencing\n",
    "as a method to make our series stationary,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize':(12,8), 'figure.dpi':120})\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, sharex=False)\n",
    "axes[0, 0].plot(df_small.sales); axes[0, 0].set_title('Original Series')\n",
    "plot_acf(df_small.sales, ax=axes[0, 1])\n",
    "\n",
    "axes[1, 0].plot(df_small.sales.diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "plot_acf(df_small.sales.diff().dropna(), ax=axes[1, 1])\n",
    "\n",
    "axes[2, 0].plot(df_small.sales.diff().diff()); axes[2, 0].set_title('2nd Order '\n",
    "                                                                  'Differencing')\n",
    "plot_acf(df_small.sales.diff().diff().dropna(), ax=axes[2, 1])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By the time the first differencing plot and its correlation plot, we can see\n",
    "that the model has achieved a decent amount of stationarity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fix Training and Test Data for Remaining Functions\n",
    "df_small = df_small.sort_values(by=['week'])\n",
    "df_model = df_small.set_index('week')\n",
    "df_small = df_small.reset_index()\n",
    "df_small = df_small[['week', 'sales']]\n",
    "train = df_small['sales'][:105]\n",
    "test = df_small['sales'][105:]\n",
    "train_model = df_model['sales'][:186]\n",
    "test_model = df_model['sales'][-16:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will test the auto_arima model to see if it performs better."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = df_model['sales']\n",
    "mod_auto_arima = auto_arima(train, start_p=0, d=1, start_q=0, max_p=5,\n",
    "                         max_d=5, max_q=5, start_P=0, D=1, start_Q=0,\n",
    "                         max_P=5, max_D=5, max_Q=5, m=12, seasonal=True,\n",
    "                         error_action='warn', trace=True,\n",
    "                         suppress_warnings=True, stepwise=True,\n",
    "                         random_state=13, n_fits=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = df['sales'][-16:]\n",
    "test = df['sales'][:16] # missing pass sixteen weeks\n",
    "model = auto_arima(train, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "model.fit(train)\n",
    "forecast = mod_auto_arima.predict(n_periods=16)\n",
    "index = pd.date_range('2022-04-03', '2022-07-17', freq='w')\n",
    "forecast = pd.DataFrame(forecast,index =index,columns=['Prediction'])\n",
    "forecast = forecast.squeeze()\n",
    "forecast_accuracy(forecast, test)\n",
    "Auto_Arima = forecast_accuracy(forecast, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = df_model['sales'][:186]\n",
    "test = df_model['sales'][186:202]\n",
    "df_temp = df_test.set_index('week')\n",
    "df_temp = df_temp[:16]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train, label='Train')\n",
    "plt.plot(test, label='Test')\n",
    "plt.plot(forecast, label='Forecast')\n",
    "plt.plot(df_temp, label='Actuals')\n",
    "plt.title('Predicted Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend(loc='upper left', fontsize=12)\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now taking a look at the other predictions compared to actuals."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_group = pd.read_csv('G:/My Drive/IN/Data/Forecast_Comparisons/updated_group_forecast2'\n",
    "                       '.csv',\n",
    "                       index_col=\"Date\",parse_dates=True)\n",
    "df_group.astype(float)\n",
    "df_group['actuals'] = test.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BigQuery = forecast_accuracy(df_group['BigQuery'], df_group['actuals'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VertexAI = forecast_accuracy(df_group['VertexAI'], df_group['actuals'])\n",
    "NeuralProphet = forecast_accuracy(df_group['NeuralProphet'], df_group['actuals'])\n",
    "Prophet = forecast_accuracy(df_group['Prophet'], df_group['actuals'])\n",
    "Forecast = forecast_accuracy(df_group['Amazon_Forecast'], df_group['actuals'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error_frame = pd.DataFrame.from_dict(VertexAI, orient='index')\n",
    "error_frame[2] = pd.DataFrame.from_dict(BigQuery, orient='index')\n",
    "error_frame[3] = pd.DataFrame.from_dict(NeuralProphet, orient='index')\n",
    "error_frame[4] = pd.DataFrame.from_dict(Prophet, orient='index')\n",
    "error_frame[5] = pd.DataFrame.from_dict(Forecast, orient='index')\n",
    "error_frame = error_frame.set_axis(['VertexAI', 'BigQuery', 'NeuralProphet',\n",
    "                                    'Prophet', 'Amazon_Forecast'], axis=1, inplace=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = df_group.index\n",
    "Actuals = df_temp\n",
    "VertexAI = df_group['VertexAI']\n",
    "BigQuery = df_group['BigQuery']\n",
    "NeuralProphet = df_group['NeuralProphet']\n",
    "Forecast = df_group['Amazon_Forecast']\n",
    "Prophet = df_group['Prophet']\n",
    "NoPrime = df_group['NoPrime']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17, 8))\n",
    "ax  = fig.add_subplot(111)\n",
    "ax.plot(x, Actuals, c='b', label='Actuals', linewidth=7)\n",
    "ax.plot(x, VertexAI, c='r', linestyle='dashed',  label='VertexAI')\n",
    "ax.plot(x, BigQuery, c='g', linestyle='dashed', label='BigQuery')\n",
    "ax.plot(x, NeuralProphet, c='y', linestyle='dashed', label='NeuralProphet')\n",
    "ax.plot(x, Forecast, c='c', linestyle='dashed', label='Amazon Forecast')\n",
    "ax.plot(x, Prophet, c='m', linestyle='dashed', label='Prophet')\n",
    "ax.plot(x, NoPrime, c='m', linestyle='dashed', label='NoPrime')\n",
    "leg = plt.legend()\n",
    "leg_lines = leg.get_lines()\n",
    "leg_texts = leg.get_texts()\n",
    "plt.setp(leg_lines, linewidth=4)\n",
    "plt.setp(leg_texts, fontsize='large')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (in millions)')\n",
    "plt.title('Forecast Method Comparison')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scalar = np.mean(df['sales'].nlargest(n=5)) / np.mean(df['sales'])\n",
    "swap = BigQuery[14::2].values\n",
    "BigQuery[14::2] = BigQuery[14::2] + swap\n",
    "print(BigQuery[14::2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17, 8))\n",
    "ax  = fig.add_subplot(111)\n",
    "ax.plot(x, Actuals, c='b', label='Actuals', linewidth=7)\n",
    "ax.plot(x, VertexAI, c='r', linestyle='dashed',  label='VertexAI')\n",
    "ax.plot(x, BigQuery, c='g', linestyle='dashed', label='BigQuery')\n",
    "ax.plot(x, NeuralProphet, c='y', linestyle='dashed', label='NeuralProphet')\n",
    "ax.plot(x, Forecast, c='c', linestyle='dashed', label='Amazon Forecast')\n",
    "ax.plot(x, Prophet, c='m', linestyle='dashed', label='Prophet')\n",
    "ax.plot(x, NoPrime, c='m', linestyle='dashed', label='NoPrime')\n",
    "leg = plt.legend()\n",
    "leg_lines = leg.get_lines()\n",
    "leg_texts = leg.get_texts()\n",
    "plt.setp(leg_lines, linewidth=4)\n",
    "plt.setp(leg_texts, fontsize='large')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (in millions)')\n",
    "plt.title('Forecast Method Comparison')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(error_frame)\n",
    "dataframe.style.highlight_min(axis=1, color= 'blue')\n",
    "# dataframe.style.highlight_max(axis=1, color= 'yellow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just for some extra clarity, Amazon performed the best in MAPE, then BigQuery, then\n",
    "Prophet, then VertexAI, and finally NeuralProphet.\n",
    "For MSE, the order was the same.\n",
    "For MAE. the only switchup was VertexAI and Prophet, which took 3 and 4th, respectively.\n",
    "Finally, RMSE matched the order of the first two metrics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To see how these metrics are cacaluated, see this article on MAPE:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error\n",
    "\n",
    "This on MSE: https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error\n",
    "\n",
    "This on MAE: https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error\n",
    "\n",
    "Finally, we have RMSE (also known as RMS) documented here (Note: FB uses normalized\n",
    "RMSE for their ML):\n",
    "https://en.wikipedia.org/wiki/Root-mean-square_deviation\n",
    "\n",
    "I would look at this article to make up your mind on pros and cons of each:\n",
    "https://towardsdatascience.com/forecast-kpi-rmse-mae-mape-bias-cdc5703d242d\n",
    "\n",
    "But I will point out some of the largest differences. For MAPE, or Mean Absolute\n",
    "Percentage Error, the average error in low-demand periods have a disproporitionaly\n",
    "large effect durring high-demand season.\n",
    "\n",
    "MAE, or Mean Absolute Error, simply takes the absolute value of the difference between\n",
    "the prediciton and actual observations, then averages them. It does suffer from scaling\n",
    "issues, so it is often weighted appropriately.\n",
    "\n",
    "Both MAE and MAPE are very similar: MAPE is an easier to understand metric, while MAE\n",
    "is easier to understand at scale. Also, MAPE behaves poorly at zero.\n",
    "\n",
    "Root-mean-square-deviation is, in its simplest case, with an unbiased estimator, the\n",
    "same as the standard deviation. For ML purposes, minimizing RMSE is the best way to\n",
    "compare one model to another.\n",
    "\n",
    "##### Remember that this numbers do not exist in a vacuum; they are best at comparing one\n",
    "##### model to another. Comparing RMSE and MAPE might be the first step, as one is\n",
    "##### constrained and RMSE less so. Finally, none of these should be negative, or else\n",
    "##### the model needs to be re-examined."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}