{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEdi78qH1Jhq"
   },
   "source": [
    "One of the primary methods Lightweight uses is scaling and normalizing\n",
    "all of the variables. I previously did the scaling on a Tyson data set\n",
    "and got most of this to run. I left some of the code in to show\n",
    "some of the steps necessary to transform a dataset for Lightweight.\n",
    "Since I made the demo, LightweightMMM has improved some of the issues\n",
    "with their scaling and model analysis, but even running with dummy data,\n",
    "some issues are still apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "afF7ZlEz37eC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515539468,
     "user_tz": 360,
     "elapsed": 785,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 08:00:58.904597: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-21 08:00:58.904648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-21 08:00:58.904653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import jax.numpy and any other library we might need.\n",
    "import jax\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jax and Pyro are good, but they are a bit touchy and require their environments\n",
    "to be very particular."
   ],
   "metadata": {
    "id": "F-wXAuH82V3o"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "numpyro.set_host_device_count(8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_device_count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ltk-rB9y-_fh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515542590,
     "user_tz": 360,
     "elapsed": 3123,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import the relevant modules of the library\n",
    "from lightweight_mmm import lightweight_mmm\n",
    "from lightweight_mmm import optimize_media\n",
    "from lightweight_mmm import plot\n",
    "from lightweight_mmm import preprocessing\n",
    "from lightweight_mmm import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGa5iPF4zdOo"
   },
   "source": [
    "## Organising the data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AF0gS72Hhwml",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515542591,
     "user_tz": 360,
     "elapsed": 4,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R6oDCH5w4M_y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515542890,
     "user_tz": 360,
     "elapsed": 3,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "data_size = 104 + 13\n",
    "n_media_channels = 3\n",
    "n_extra_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "media_data, extra_features, target, costs = utils.simulate_dummy_data(\n",
    "    data_size=data_size,\n",
    "    n_media_channels=n_media_channels,\n",
    "    n_extra_features=n_extra_features)"
   ],
   "metadata": {
    "id": "nLnV9Dumb_7v",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515552428,
     "user_tz": 360,
     "elapsed": 9540,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This begins the process of breaking down the Tyson file into several different sections. In the next section, we convert them into a jax/numpy array and prepare them to be scaled before modeling."
   ],
   "metadata": {
    "id": "spRwCKaCa1zX"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58yFB05A4e0j"
   },
   "source": [
    "We can then split the dataset into train and test. Lets leave only the last 13 weeks for testing in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xMMKo3fK4UN4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515552876,
     "user_tz": 360,
     "elapsed": 459,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Split and scale data.\n",
    "split_point = data_size - 13\n",
    "# Media data\n",
    "media_data_train = jnp.asarray(media_data[:split_point])\n",
    "media_data_test = jnp.asarray(media_data[split_point:])\n",
    "# Extra features\n",
    "extra_features_train = jnp.asarray(extra_features[:split_point])\n",
    "extra_features_test = jnp.asarray(extra_features[split_point:])\n",
    "# Target\n",
    "target_train = jnp.asarray(target[:split_point])\n",
    "target_test = jnp.asarray(target[split_point:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0pZBcF14lPV"
   },
   "source": [
    "Scaling is essential for many modelling problems and this one is no exception.\n",
    "\n",
    "We provide the class `CustomScaler` which behaves accordingly with `sklearn`\n",
    "scalers.\n",
    "\n",
    "In most cases you will need 3 or 4 scalers. One scaler for the media data, one\n",
    "for the target and one for costs. Optionally if you are adding extra features\n",
    "those might need an extra scaler. **It is very important that you save and\n",
    "\"carry with you\" those scalers throughout your MMM journey as LighweightMMM will\n",
    "allow you to re-insert these scalers at different points to ensure everything is\n",
    "always in the correct scale and results. If some results don't make sense, it\n",
    "might be a scaling problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGAjohQH4qCO"
   },
   "source": [
    "A few more details on CustomScaler usage:\n",
    "\n",
    "This scaler can be used in two fashions for both the multiplication and division\n",
    "operation. \n",
    "- By specifying a value to use for the scaling operation. \n",
    "- By specifying an operation used at column level to calculate the value for the\n",
    "actual scaling operation.\n",
    "\n",
    "Eg. if one wants to scale the dataset by multiply by 100 you can directly pass\n",
    "multiply_by=100. Value can also be an array of an appropriate shape by which\n",
    "to divide or multiply the data. But if you want to multiply by the mean value of each\n",
    "column, then you can pass multiply_operation=jnp.mean (or any other operation\n",
    "desired).\n",
    "\n",
    "Operation parameters have the upper hand in the cases where both values and\n",
    "operations are passed, values will be ignored in this case.\n",
    "\n",
    "Consult the full class documentation if you still need to know more.\n",
    "\n",
    "In this demo we divide the data on media, extra features and the target by their mean to ensure that the result has a mean of 1. This allows the model to be agnostic to the scale of the inputs (e.g. a user can use either the number of sales or the value of sales). The costs are not used in the model directly, they are only used to inform the prior distributions on the media variables (see the [model documentation](https://lightweight-mmm.readthedocs.io/en/latest/models.html) here). These costs have been scaled down by multiplying by 0.15 to reflect typical ranges in MMMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This scaling is quite useful, but for some variables it is reversible, and others it is not. It only affects a few graphs, however."
   ],
   "metadata": {
    "id": "55y0ypY5bHng"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B-19ZTfx4uh5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515553923,
     "user_tz": 360,
     "elapsed": 1049,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "media_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "extra_features_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "target_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "cost_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean, multiply_by=0.15)\n",
    "\n",
    "media_data_train = media_scaler.fit_transform(media_data_train)\n",
    "extra_features_train = extra_features_scaler.fit_transform(extra_features_train)\n",
    "target_train = target_scaler.fit_transform(target_train)\n",
    "costs = cost_scaler.fit_transform(costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking data quality\n",
    "Before putting data into a model, the data should always be examined by hand to make sure everything is correct, and to check for potential issues that might affect the modeling process. We include a data quality check in LMMM which checks for a few common issues. This is not an exhaustive set of checks, however, and most of the exploratory data anlysis will still have do be done manually based on your judgment."
   ],
   "metadata": {
    "id": "1Hr4SohFdLvH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# correlations, variances, spend_fractions, variance_inflation_factors = preprocessing.check_data_quality(\n",
    "#     media_data=media_scaler.transform(media_data),\n",
    "#     target_data=target_scaler.transform(target),\n",
    "#     cost_data=costs,\n",
    "#     extra_features_data=extra_features_scaler.transform(extra_features))"
   ],
   "metadata": {
    "id": "hbE10KMjdRgu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515556809,
     "user_tz": 360,
     "elapsed": 2889,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 1: Checking the correlation matrix\n",
    "\n",
    "The below cell shows the correlation matrix between all the features, and between each feature and the target. Very positive or very negative correlations (with an absolute value above, say, 0.7 or so) should be treated with caution. In this case you might consider dropping or merging highly correlated features."
   ],
   "metadata": {
    "id": "qZTtBovcdYhH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# correlations[0].style.background_gradient(cmap='RdBu', vmin=-1, vmax=1).format(precision = 3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TEW5w3f7dcOn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515556815,
     "user_tz": 360,
     "elapsed": 21,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    },
    "outputId": "b320f840-6c7a-4bd7-fa34-94abb98f2c27"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 2: Checking the variances\n",
    "\n",
    "The below cell shows the variance of each feature over time. Variances which are lower than the specified low_variance_threshold or higher than the specified high_variance_threshold are marked in red. Make sure you are passing the scaled versions of your media_data and extra_features_data to the data quality checker for these variances before running this check!"
   ],
   "metadata": {
    "id": "8rTy1B0qdlYH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# def highlight_variances(x: float,\n",
    "#                         low_variance_threshold: float=1.0e-3,\n",
    "#                         high_variance_threshold: float=3.0) -> str:\n",
    "#\n",
    "#     if x < low_variance_threshold or x > high_variance_threshold:\n",
    "#       weight = 'bold'\n",
    "#       color = 'red'\n",
    "#     else:\n",
    "#       weight = 'normal'\n",
    "#       color = 'black'\n",
    "#     style = f'font-weight: {weight}; color: {color}'\n",
    "#     return style\n",
    "#\n",
    "# variances.style.applymap(highlight_variances).format(precision = 4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "YsArRYwQdpRn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515556816,
     "user_tz": 360,
     "elapsed": 13,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    },
    "outputId": "80e6f5d7-f249-41a3-cbf6-e9de99fdcac4"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 3: Checking the spend fractions\n",
    "\n",
    "This check is very straightforward. LMMM uses the total spend for each channel to set the prior on the channel's media contribution coefficient, as well as to calculate ROI later in the analysis. Thus the spend for each channel must be positive (not negative or zero), and ideally each channel should not be a negligibly small fraction of the total spend as well."
   ],
   "metadata": {
    "id": "t6wdBCyJdxA4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# def highlight_low_spend_fractions(x: float,\n",
    "#                                   low_spend_threshold: float=0.01) -> str:\n",
    "#     if x < low_spend_threshold:\n",
    "#       weight = 'bold'\n",
    "#       color = 'red'\n",
    "#     else:\n",
    "#       weight = 'normal'\n",
    "#       color = 'black'\n",
    "#     style = f'font-weight: {weight}; color: {color}'\n",
    "#     return style\n",
    "#\n",
    "# spend_fractions.style.applymap(highlight_low_spend_fractions).format(precision = 4)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "hpIFgtnTdy0I",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515556908,
     "user_tz": 360,
     "elapsed": 104,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    },
    "outputId": "b228cc85-73f9-43e6-8b5a-cbe211921e8d"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 4: Checking the variance inflation factors\n",
    "\n",
    "While checking the correlation matrix in step 1 is usually sufficient for detetcing obvious multicollinearity in a dataset, the variance inflation factor is technically the best metric for identifying multicollinear features. Here we list the variance inflation factors for all features. If the number is too high (we use a threshold here of 7, but feel free to adjust to your use case) you might consider dropping or merging features with high variance inflation factors."
   ],
   "metadata": {
    "id": "DFFrwbLxd7Lo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# def highlight_high_vif_values(x: float,\n",
    "#                               high_vif_threshold: float=7.0) -> str:\n",
    "#     if x > high_vif_threshold:\n",
    "#       weight = 'bold'\n",
    "#       color = 'red'\n",
    "#     else:\n",
    "#       weight = 'normal'\n",
    "#       color = 'black'\n",
    "#     style = f'font-weight: {weight}; color: {color}'\n",
    "#     return style\n",
    "#\n",
    "# variance_inflation_factors.style.applymap(highlight_high_vif_values).format(precision = 4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "6a9aL13Kd9B4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515557522,
     "user_tz": 360,
     "elapsed": 615,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    },
    "outputId": "34e76304-56d8-4aac-c81f-85147f2b5bf8"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiJBiIjVJ4h9"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNiMpZSjJ8KF"
   },
   "source": [
    "The currently available models are the following: \n",
    "- hill_adstock \n",
    "- adstock \n",
    "- carryover"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In my research I learned that the carryover model with a seasonality degree of 1 prorivded the best results."
   ],
   "metadata": {
    "id": "86l2u4ujB_0y"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nTmDycd3J-Iw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515557523,
     "user_tz": 360,
     "elapsed": 4,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "mmm = lightweight_mmm.LightweightMMM(model_name=\"carryover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2XCraqXKA7B"
   },
   "source": [
    "Training the model will require the following mandatory parameters: \n",
    "- media\n",
    "- total_costs (one value per channel) \n",
    "- target\n",
    "\n",
    "We can optionally also pass the following: \n",
    "- extra_features: Other variables to add to the model. \n",
    "- degrees_seasonality: Number of degrees to use for seasonality. Default is 3. \n",
    "- seasonality_frequency: Frequency of the time period used. Default is 52 as in 52 weeks per year. \n",
    "- media_names: Names of the media channels passed. \n",
    "- number_warmup: Number of warm up samples. Default is 1000. \n",
    "- number_samples: Number of samples during sampling. Default is 1000. \n",
    "- number_chains: Number of chains to sample. Default is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aza-wH0N2d52",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671515557523,
     "user_tz": 360,
     "elapsed": 3,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "number_warmup=1000\n",
    "number_samples=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1682879,
     "status": "ok",
     "timestamp": 1671517240399,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "FtVwGQITKDQp",
    "outputId": "61716653-5b47-4a9d-f8b9-c6e8e93feb27",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/envs/lightweight/lib/python3.7/site-packages/lightweight_mmm/lightweight_mmm.py:361: UserWarning: There are not enough devices to run parallel chains: expected 2 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(2)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  num_chains=number_chains)\n",
      "warmup:  16%|█▌        | 322/2000 [03:59<20:49,  1.34it/s, 1023 steps of size 1.46e-03. acc. prob=0.82]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_60454/3222907894.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0;31m# weekday_seasonality=True,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;31m# seasonality_frequency=365,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m     seed=SEED)\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/lightweight/lib/python3.7/site-packages/lightweight_mmm/lightweight_mmm.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, media, media_prior, target, extra_features, degrees_seasonality, seasonality_frequency, weekday_seasonality, media_names, number_warmup, number_samples, number_chains, target_accept_prob, init_strategy, custom_priors, seed)\u001B[0m\n\u001B[1;32m    370\u001B[0m         \u001B[0mtransform_function\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_model_transform_function\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    371\u001B[0m         \u001B[0mweekday_seasonality\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mweekday_seasonality\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 372\u001B[0;31m         custom_priors=custom_priors)\n\u001B[0m\u001B[1;32m    373\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    374\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcustom_priors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcustom_priors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/lightweight/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001B[0m\n\u001B[1;32m    595\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    596\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchain_method\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"sequential\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 597\u001B[0;31m                 \u001B[0mstates\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_laxmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpartial_map_fn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    598\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchain_method\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"parallel\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    599\u001B[0m                 \u001B[0mstates\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpartial_map_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/lightweight/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001B[0m in \u001B[0;36m_laxmap\u001B[0;34m(f, xs)\u001B[0m\n\u001B[1;32m    158\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_get_value_from_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 160\u001B[0;31m         \u001B[0mys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    161\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtree_map\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mjnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/lightweight/lib/python3.7/site-packages/numpyro/infer/mcmc.py\u001B[0m in \u001B[0;36m_single_chain_mcmc\u001B[0;34m(self, init, args, kwargs, collect_fields)\u001B[0m\n\u001B[1;32m    414\u001B[0m             \u001B[0mprogbar_desc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_get_progbar_desc_str\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlower_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mphase\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    415\u001B[0m             \u001B[0mdiagnostics_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdiagnostics\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 416\u001B[0;31m             \u001B[0mnum_chains\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_chains\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchain_method\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"parallel\"\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    417\u001B[0m         )\n\u001B[1;32m    418\u001B[0m         \u001B[0mstates\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcollect_vals\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/lightweight/lib/python3.7/site-packages/numpyro/util.py\u001B[0m in \u001B[0;36mfori_collect\u001B[0;34m(lower, upper, body_fun, init_val, transform, progbar, return_last_val, collection_size, thinning, **progbar_opts)\u001B[0m\n\u001B[1;32m    356\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mupper\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    357\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 358\u001B[0;31m                     \u001B[0mvals\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_body_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    359\u001B[0m                     \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_description\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprogbar_desc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrefresh\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    360\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mdiagnostics_fn\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/lightweight/lib/python3.7/site-packages/jax/_src/api.py\u001B[0m in \u001B[0;36mcache_miss\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    621\u001B[0m         jax.config.jax_debug_nans or jax.config.jax_debug_infs):\n\u001B[1;32m    622\u001B[0m       \u001B[0mexecute\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_xla_call_impl_lazy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfun_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mtracers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 623\u001B[0;31m       \u001B[0mout_flat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_bind_continuation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs_flat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    624\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    625\u001B[0m       out_flat = call_bind_continuation(\n",
      "\u001B[0;32m~/anaconda3/envs/lightweight/lib/python3.7/site-packages/jax/_src/dispatch.py\u001B[0m in \u001B[0;36m_execute_compiled\u001B[0;34m(name, compiled, input_handler, output_buffer_counts, result_handler, has_unordered_effects, ordered_effects, kept_var_idx, has_host_callbacks, *args)\u001B[0m\n\u001B[1;32m    893\u001B[0m       \u001B[0mruntime_token\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    894\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 895\u001B[0;31m     \u001B[0mout_flat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompiled\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0min_flat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    896\u001B[0m   \u001B[0mcheck_special\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout_flat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    897\u001B[0m   \u001B[0mout_bufs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0munflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout_flat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_buffer_counts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# For replicability in terms of random number generation in sampling\n",
    "# reuse the same seed for different trainings.\n",
    "mmm.fit(\n",
    "    media=media_data_train,\n",
    "    media_prior=costs,\n",
    "    target=target_train,\n",
    "    extra_features=extra_features_train,\n",
    "    # media_names=('Influencer_I', 'Social_Media_I', 'Radio_I'),\n",
    "    # number_warmup=number_warmup,\n",
    "    number_samples=number_samples,\n",
    "    # degrees_seasonality=1,\n",
    "    # weekday_seasonality=True,\n",
    "    # seasonality_frequency=365,\n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qwwi7E61KKdL"
   },
   "source": [
    "You can check the summary of your trace by printing a summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is important that each r_hat is below 1.1; it is here."
   ],
   "metadata": {
    "id": "Ivf3rHpu6EIX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1671517240522,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "sJUiM-1vKMt_",
    "outputId": "9c065b35-d275-46ad-b301-e22079de6536",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "mmm.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7npbmDKfKNMX"
   },
   "source": [
    "We can visualise the posterior distributions of the media effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 907,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1671517241188,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "BpqYqFNqKNTc",
    "outputId": "25870b14-38dd-4bb5-c260-d161dbd75f94"
   },
   "outputs": [],
   "source": [
    "# channel_names = ['Influencers', 'Social Media', 'Radio']\n",
    "# plot.plot_media_channel_posteriors(media_mix_model=mmm, channel_names=channel_names)\n",
    "plot.plot_media_channel_posteriors(media_mix_model=mmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[optional]\n",
    "\n",
    "LightweightMMM also allows you to visualize the prior and posterior distributions for every model parameter at once. Note that we use a kernel density estimator to smooth these distributions for easier interpretability; you may need to adjust the bandwidth of the smoother depending on the shapes of your distributions. Also, this plot can take several minutes to run, especially if using geo-level models. Lowering the number_of_samples_for_prior or restricting to a subset of selected_features can speed up the runtime."
   ],
   "metadata": {
    "id": "20VMDg9_mTnL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plot.plot_prior_and_posterior(media_mix_model=mmm)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8KLDT5SAmXbz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671517251726,
     "user_tz": 360,
     "elapsed": 10547,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    },
    "outputId": "2efbd4e9-2b72-4d13-be04-cb1d30d65e43"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwgyS0W-KNbx"
   },
   "source": [
    "One can also check your model's fit to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is one such graph that does not work; it does not yet properly treat the target_scaler object into a decomposable one, nor does the documentation suggest any fixes,"
   ],
   "metadata": {
    "id": "dk9DEUhRbbFM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tw-TF20IKNi5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1671517311448,
     "user_tz": 360,
     "elapsed": 185,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    },
    "outputId": "1f30fcfb-0076-4e01-e85b-eac47cef6ce4"
   },
   "outputs": [],
   "source": [
    "# Here is another example where we can pass the target scaler if you want the plot to be in the \"not scaled scale\"\n",
    "plot.plot_model_fit(mmm, target_scaler=target_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4v50_s1sKNrN"
   },
   "source": [
    "If one wants to run predictions on unseen data they can rely on the `predict`\n",
    "method:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "By exporting this new_predictions file, Bayesian distributions will allow predictive estimates."
   ],
   "metadata": {
    "id": "mOTpcTckb7f0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1346,
     "status": "ok",
     "timestamp": 1671517344458,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "yQuUUolAKN0W",
    "outputId": "fea4b19e-052d-4092-d3d5-69e29bcbc1a1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# We have to scale the test media data if we have not done so before.\n",
    "new_predictions = mmm.predict(media=media_scaler.transform(media_data_test),\n",
    "                              extra_features=extra_features_scaler.transform(extra_features_test),\n",
    "                              seed=SEED)\n",
    "new_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Like the graph above it, the reliance on GPUs from NumPyro and Jax prevent some functions from working."
   ],
   "metadata": {
    "id": "kIF0K0GgcAY0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0a9JyiMKN8q",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1671517357813,
     "user_tz": 360,
     "elapsed": 887,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    },
    "outputId": "d2230c74-00dd-47ba-8e0d-a8e5c8b4117b"
   },
   "outputs": [],
   "source": [
    "plot.plot_out_of_sample_model_fit(out_of_sample_predictions=new_predictions,\n",
    "                                 out_of_sample_target=target_scaler.transform(target[split_point:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDMW2Pe-KOEm"
   },
   "source": [
    "### Media insights"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "prediction = mmm.predict(\n",
    "    media=media_data_test,\n",
    "    extra_features=extra_features_test,\n",
    "    target_scaler=target_scaler\n",
    ")"
   ],
   "metadata": {
    "id": "hzvwsgLFwJUu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671517436028,
     "user_tz": 360,
     "elapsed": 371,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot.plot_response_curves(media_mix_model=mmm, media_scaler=media_scaler, target_scaler=target_scaler)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PK5H_oT1w6Hf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671517442428,
     "user_tz": 360,
     "elapsed": 3933,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    },
    "outputId": "d100a011-a2ae-4cf3-af3b-7881ac143625"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQUnoKKQKONT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671517447318,
     "user_tz": 360,
     "elapsed": 524,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "media_contribution, roi_hat = mmm.get_posterior_metrics(target_scaler=target_scaler, cost_scaler=cost_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ARNXcQnAjjt"
   },
   "source": [
    "We can quickly visualise the estimated media & baseline contribution over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 559,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2237,
     "status": "ok",
     "timestamp": 1671517451734,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "G7uogajxApbw",
    "outputId": "ebefb610-b1de-4e93-9478-14fabcbb32ea"
   },
   "outputs": [],
   "source": [
    "plot.plot_media_baseline_contribution_area_plot(media_mix_model=mmm,\n",
    "                                                target_scaler=target_scaler,\n",
    "                                                fig_size=(30,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szhjLnpHKOWc"
   },
   "source": [
    "We can quickly visualise the estimated media contributions with their respective\n",
    "credibility intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 480,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1671517455514,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "Hi3nJDE8KOfk",
    "outputId": "88378aba-66a0-40b0-eb7a-8add1755e62e"
   },
   "outputs": [],
   "source": [
    "plot.plot_bars_media_metrics(metric=media_contribution, metric_name=\"Media Contribution Percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 480,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1671517462729,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "oC82BdUJKOoT",
    "outputId": "7b3ced1e-83d8-41f5-d020-82b009abbff7"
   },
   "outputs": [],
   "source": [
    "plot.plot_bars_media_metrics(metric=roi_hat, metric_name=\"ROI hat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR_m4DvmKOx0"
   },
   "source": [
    "Another vital question we can solve with MMMs is how each media channel behaves\n",
    "individually as we invest more in it.\n",
    "\n",
    "For that we can plot the curve response of all media channels with the following\n",
    "function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 1000,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1562,
     "status": "ok",
     "timestamp": 1671517468300,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "w6DfZdyUKO6k",
    "outputId": "8af53875-4948-431a-ade6-597691c987a5"
   },
   "outputs": [],
   "source": [
    "plot.plot_response_curves(\n",
    "    media_mix_model=mmm, target_scaler=target_scaler, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNEQkwvZKPDR"
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IslzAcNKPLO"
   },
   "source": [
    "The optimization is meant to solve the budget allocation questions for you.\n",
    "First you need to provide for how long you want to optimize your budget (eg. 15\n",
    "weeks in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULQZGNMlKPT6"
   },
   "source": [
    "The optimization values will be bounded by +- 20% of the max and min historic\n",
    "values used for training. Which means the optimization won't recommend to\n",
    "completely change your strategy but how to make some budget re-allocation.\n",
    "\n",
    "You can change that percentage with the following parameters: -\n",
    "bounds_lower_pct - bounds_upper_pct\n",
    "\n",
    "Which can hold 1 value for all channels or 1 value per channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDw5WtooKPde"
   },
   "source": [
    "Prices are the average price you would expect for the media units of each\n",
    "channel. If your data is already a money unit (eg. $) your prices should be an\n",
    "array of 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3TaoXYjKPmr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671517476978,
     "user_tz": 360,
     "elapsed": 264,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "prices = jnp.ones(mmm.n_media_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yF6JjbqPKP2R"
   },
   "source": [
    "The budget is how much one would like to allocate throughtout the total of\n",
    "`n_time_periods`. Make sure this amount is inline with the historic spend or\n",
    "otherwise some conditions/bounds in the optimization might not be met. Testing this with data made from the Utils package, it cannot successfully perform an optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReGi5AGTL86q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1671517481463,
     "user_tz": 360,
     "elapsed": 975,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "n_time_periods = 12\n",
    "budget = (jnp.sum(jnp.dot(prices, jnp.asarray(media_data).mean(axis=0)))* n_time_periods) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11178,
     "status": "ok",
     "timestamp": 1671517496753,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "qtt9L4aPL-cs",
    "outputId": "1fcad1b9-c159-456b-bf64-f7775c19610c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Run optimization with the parameters of choice.\n",
    "solution, kpi_without_optim, previous_budget_allocation = optimize_media.find_optimal_budgets(\n",
    "    n_time_periods=n_time_periods,\n",
    "    media_mix_model=mmm,\n",
    "    extra_features=extra_features_scaler.transform(extra_features_test)[:n_time_periods],\n",
    "    budget=budget,\n",
    "    prices=prices,\n",
    "    media_scaler=media_scaler,\n",
    "    target_scaler=target_scaler,\n",
    "    bounds_upper_pct=10,\n",
    "    max_iterations=200,\n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1vZcsNYjNyA"
   },
   "source": [
    "If your media data is not in money unit (eg. impressions, clicks, GRPs, etc.), you would need to store the cost per values (eg. CPC) in the prices array and multiply it by solution.x to get the recommended budget allocation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1671517564804,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "C2FIJu82MAk9",
    "outputId": "0fe61734-873f-4b53-e458-85f8970ef8b3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Obtain the optimal weekly allocation.\n",
    "optimal_buget_allocation = prices * solution.x\n",
    "optimal_buget_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1671517572403,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "XS1rHOfaMCBt",
    "outputId": "76b7e3bf-f77d-4151-eb8b-4d844d4692f3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Both values should be very close in order to compare KPI\n",
    "budget, optimal_buget_allocation.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvMc28XKMEt_"
   },
   "source": [
    "We can double check the budget constraint was met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1671517577934,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "ffZl2W-pMFrD",
    "outputId": "0966b2e6-e11f-4ba9-8b6e-b08362c2f5a8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "# Both numbers should be almost equal\n",
    "budget, jnp.sum(solution.x * prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aK21EDOyzDC3"
   },
   "source": [
    "## We can plot the following:\n",
    "1. Pre post optimization budget allocation comparison for each channel\n",
    "2. Pre post optimization predicted target variable comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "height": 1000,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1671517580871,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     },
     "user_tz": 360
    },
    "id": "0jRI8ynqzFip",
    "outputId": "f486c6b4-0c7a-4dcd-f2c9-493efdfc4827"
   },
   "outputs": [],
   "source": [
    "# Plot out pre post optimization budget allocation and predicted target variable comparison.\n",
    "plot.plot_pre_post_budget_allocation_comparison(media_mix_model=mmm, \n",
    "                                                kpi_with_optim=solution['fun'], \n",
    "                                                kpi_without_optim=kpi_without_optim,\n",
    "                                                optimal_buget_allocation=optimal_buget_allocation, \n",
    "                                                previous_budget_allocation=previous_budget_allocation, \n",
    "                                                figure_size=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3UbFu9VSRq9"
   },
   "source": [
    "## Saving the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aetzKyUOBhwm",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1671517252901,
     "user_tz": 360,
     "elapsed": 7,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "# # We can use the utilities for saving models to disk.\n",
    "# file_path = \"media_mix_model.pkl\"\n",
    "# utils.save_model(media_mix_model=mmm, file_path='C:/Users/norri/Desktop/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74Fx-1N4HQsJ",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1671517252901,
     "user_tz": 360,
     "elapsed": 7,
     "user": {
      "displayName": "Matthew Norris",
      "userId": "17841799204930071289"
     }
    }
   },
   "outputs": [],
   "source": [
    "# # Once saved one can load the models.\n",
    "# loaded_mmm = utils.load_model(file_path=file_path)\n",
    "# loaded_mmm.trace[\"coef_media\"].shape # Example of accessing any of the model values."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "provenance": [
    {
     "file_id": "https://github.com/google/lightweight_mmm/blob/main/examples/simple_end_to_end_demo.ipynb",
     "timestamp": 1659404247400
    },
    {
     "file_id": "/piper/depot/google3/third_party/professional_services/solutions/lightweight_mmm/examples/simple_end_to_end_demo.ipynb",
     "timestamp": 1651870257220
    },
    {
     "file_id": "1pa-fx5Uxyj9IiEM02BmGZD3OkTAu7RPw",
     "timestamp": 1643805668822
    }
   ],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "premium"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
