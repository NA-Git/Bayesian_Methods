{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIqrKOFaKgk9"
   },
   "source": [
    "# An Example of Nowcasting with DLT\n",
    "\n",
    "This session demos a nowcasting problem using Orbit to explains the data. Since this is a nowcasting problem, we can adopt concurrent information to explain the data such as the search queries and stock market indices happened in the same period. Such idea was also explored in the Bayesian Structural Time-Series(BSTS) paper [Scott and Varan (2013)](https://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf). In particular, the session covers \n",
    "\n",
    "- orbit installation\n",
    "- a forecasting task on iclaims dataset\n",
    "- a simple DLT model\n",
    "- DLT model with regression settings\n",
    "- models diagnostic\n",
    "- regression with informative priors\n",
    "\n",
    "For more examples, check out the [Github](https://github.com/uber/orbit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqUh3pnKJwAY"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIZzH4HsJ6Hc"
   },
   "source": [
    "Read the requirements file and make sure you have a C++ compiler for PyStan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAcUmw6KHYgU",
    "outputId": "c901ec63-6bbf-4a76-ead8-33ef6702e195",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/uber/orbit.git@dev\n",
    "!pip install matplotlib==3.1.3\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TafwfAxhJ2o3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import orbit\n",
    "from orbit.utils.dataset import load_iclaims\n",
    "from orbit.models import DLT\n",
    "from orbit.diagnostics.plot import plot_predicted_data, plot_predicted_components\n",
    "from orbit.diagnostics.metrics import smape\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "seed=2022"
   ],
   "metadata": {
    "id": "JR5-OgjSUds7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJyAnoornSqB",
    "outputId": "c80ab120-7a4b-4632-dda1-fdc2d3a2403b"
   },
   "outputs": [],
   "source": [
    "print(orbit.__version__)\n",
    "print(os.name)\n",
    "print(platform.system())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgP02fRURpIq"
   },
   "outputs": [],
   "source": [
    "def mae(x, y):\n",
    "    return np.mean(np.abs(x - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukVfrkx_L6LT"
   },
   "source": [
    "# US Weekly Initial Claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYeyUi6fL2ja"
   },
   "source": [
    "The *iclaims* data contains the weekly initial claims for US unemployment benefits against a few related google trend queries (unemploy, filling and job) \n",
    "from Jan 2010 - June 2018. This dataset was used in the original Bayesian Structural Time-Series paper [Scott and Varan (2013)](https://people.ischool.berkeley.edu/~hal/Papers/2013/pred-present-with-bsts.pdf) as well.\n",
    "\n",
    "Number of claims are obtained from [Federal Reserve Bank of St. Louis](https://fred.stlouisfed.org/series/ICNSA) while regressors such as google queries are obtained through [Google Trends API](https://trends.google.com/trends/?geo=US).\n",
    "\n",
    "In order to use this data to nowcast the US unemployment claims considering the impact of COVID-19, we extended the dataset to Jan 2021 and added the [S&P 500 (^GSPC)](https://finance.yahoo.com/quote/%5EGSPC/history?period1=1264032000&period2=1611187200&interval=1wk&filter=history&frequency=1wk&includeAdjustedClose=true) and [VIX](https://finance.yahoo.com/quote/%5EVIX/history?p=%5EVIX) Index historical data for the same period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akdV4LG2NRyr"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = load_iclaims(end_date='2021-01-03')\n",
    "df = df[['week', 'claims', 'trend.unemploy', 'trend.job', 'sp500', 'vix']]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For SP500 index, it is more reasonable to examine the change of the index which naturally captures the shock of market's belief of the economics in future periods."
   ],
   "metadata": {
    "id": "twArsNi78aK_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df[['sp500']] = df[['sp500']].diff()\n",
    "df = df[1:].reset_index(drop=True)\n",
    "\n",
    "date_col = 'week'\n",
    "response_col = 'claims'\n",
    "df.dtypes"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdtYB32gdKSm",
    "outputId": "d2f4a451-b78f-4043-e3d5-62c6b27a202f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zRyyzIdlNTSi",
    "outputId": "4f14a9f1-2ea7-4a41-a077-892fc0ffcd6f"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMPg4sW4NsR8"
   },
   "source": [
    "We can see from the charts below, there are seasonlity, trend, and as well as a huge changpoint due the impact of COVID-19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "mD4KLcIDNVV_",
    "outputId": "55350a03-4ce6-4e21-e5cc-267d82db7ffa"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(16, 8))\n",
    "axs[0, 0].plot(df['week'], df['claims'])\n",
    "axs[0, 0].set_title('Unemployment Claims')\n",
    "axs[0, 1].plot(df['week'], df['trend.unemploy'], 'tab:orange')\n",
    "axs[0, 1].set_title('Google trend - unemploy')\n",
    "axs[1, 0].plot(df['week'], df['vix'], 'tab:green')\n",
    "axs[1, 0].set_title('VIX')\n",
    "axs[1, 1].plot(df['week'], df['sp500'], 'tab:red')\n",
    "axs[1, 1].set_title('S&P500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwoeYdLvOwoY"
   },
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0bONJUP8vMz"
   },
   "source": [
    "To make Bayesian priors comparable across regressors, we need some transformation across regressors. For simplicity, `MixMaxScalar()` is used here. In practice, one can consider standardizing process instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGqqs1q0NrRk"
   },
   "outputs": [],
   "source": [
    "test_size = 12\n",
    "train_df = df[:-test_size].reset_index(drop=True)\n",
    "test_df = df[-test_size:].reset_index(drop=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_df[['claims', 'trend.unemploy', 'trend.job', 'sp500', 'vix']] = scaler.fit_transform(train_df[['claims', 'trend.unemploy', 'trend.job', 'sp500', 'vix']])\n",
    "test_df[['claims', 'trend.unemploy', 'trend.job', 'sp500', 'vix']] = scaler.transform(test_df[['claims', 'trend.unemploy', 'trend.job', 'sp500', 'vix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nRsAtnjO-cG"
   },
   "source": [
    "# Simple DLT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNejs5HEO4Wi",
    "outputId": "3779874d-a9d4-4efb-e92f-b23efb633e26"
   },
   "outputs": [],
   "source": [
    "dlt = DLT(\n",
    "    response_col=response_col,\n",
    "    date_col=date_col,\n",
    "    seasonality=52,\n",
    "    num_warmup=4000,\n",
    "    num_sample=1000,\n",
    "    estimator='stan-mcmc',\n",
    "    seed=2022,\n",
    ")\n",
    "\n",
    "dlt.fit(df=train_df)\n",
    "predicted_df = dlt.predict(df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "id": "4DcyujW4PEcu",
    "outputId": "10e1d46d-3e5b-4c18-d2db-634e48b64eff"
   },
   "outputs": [],
   "source": [
    "_ = plot_predicted_data(training_actual_df=train_df, \n",
    "                        predicted_df=predicted_df, \n",
    "                        date_col=date_col, \n",
    "                        actual_col=response_col, \n",
    "                        test_actual_df=test_df,\n",
    "                        title='DLT with Linear Global Trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIKAUR5-PnSJ"
   },
   "source": [
    "# DLT With Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rQHtZyyPuD1"
   },
   "source": [
    "In this session, a regression component is added on top of the `DLT` model.\n",
    "\n",
    "The regressor columns can be supplied via argument `regressor_col`.  Recall the regression formula in **DLT**:\n",
    "\n",
    "$$\n",
    "\\hat{y}_t =\\mu_t + s_t + r_t \\\\\n",
    "r_t = \\sum_{j}\\beta_j x_{jt} \\\\\n",
    "\\beta_j ~\\sim \\mathcal{N}(\\mu_j, \\sigma_j^2)\n",
    "$$\n",
    "\n",
    "Let's use the default (non-informative priors) where $\\mu_j = 0$ and $\\sigma_j = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5myLe75QBsv"
   },
   "source": [
    "## Regular Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0umPGH1PsmK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6b121119-9644-48fd-f076-92fa174ed821"
   },
   "outputs": [],
   "source": [
    "dlt_reg = DLT(\n",
    "    response_col=response_col, \n",
    "    date_col=date_col,\n",
    "    regressor_col=['trend.unemploy', 'trend.job', 'sp500', 'vix'],\n",
    "    seasonality=52,\n",
    "    num_warmup=4000,\n",
    "    num_sample=1000,\n",
    "    estimator='stan-mcmc',\n",
    "    seed=2022,\n",
    ")\n",
    "\n",
    "dlt_reg.fit(df=train_df)\n",
    "predicted_df_reg = dlt_reg.predict(test_df, decompose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "k7GlGkuQxWhB",
    "outputId": "f8fda1e4-f916-4118-8912-36cac4663f46"
   },
   "outputs": [],
   "source": [
    "_ = plot_predicted_data(training_actual_df=train_df, predicted_df=predicted_df_reg, \n",
    "                        date_col=date_col, actual_col=response_col, test_actual_df=test_df,\n",
    "                        use_orbit_style=False,\n",
    "                        title='DLT with Regular Regresion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-k69AWexUsq"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msHJC7T4QIo4"
   },
   "source": [
    "The estimated regressor coefficients can be retrieved via `.get_regression_coefs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "_1jCWeEeQAFG",
    "outputId": "1e165c10-70f2-4ef8-b373-fd89bb9a3e92"
   },
   "outputs": [],
   "source": [
    "dlt_reg.get_regression_coefs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8jzqxV876Hd"
   },
   "source": [
    "# Diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8O3j7F287k9"
   },
   "source": [
    "## Decomposition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et-wIx_Q9QdY"
   },
   "source": [
    "`plot_predicted_components` is the utility to plot each component separately. This is useful when one wants to look into the model prediction results and inspect each component separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "WxSE_VFg86xz",
    "outputId": "bfc4e4fd-762e-4155-f4dd-b8697a82d322"
   },
   "outputs": [],
   "source": [
    "_ = plot_predicted_components(predicted_df_reg, date_col, \n",
    "                              use_orbit_style=False,\n",
    "                              plot_components=['prediction', 'trend', 'seasonality', 'regression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PL0RMStc_KzY"
   },
   "source": [
    "## Posterior Diagnostic Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1O0Xm6J4_N9l"
   },
   "source": [
    "A few diagnostic plots is recommended for Orbit models. With `version>=1.1.0`,\n",
    "\n",
    "These plots can be created directly in [Arivz](https://github.com/arviz-devs/arviz) which is a Python package for exploratory analysis of Bayesian models, includes functions for posterior analysis, data storage, model checking, comparison and diagnostics. Two plots can be found below:\n",
    "\n",
    "1. Trace plot\n",
    "2. Pair density plot\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import arviz as az\n",
    "az.style.use('arviz-darkgrid')"
   ],
   "metadata": {
    "id": "3_wavZPdSuAW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJuArlba_vF8"
   },
   "source": [
    "### Trace plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78yVcCVP_6L-"
   },
   "source": [
    "Trace plot shows the iterations of each paramter over the Markov chian sampling process. Trace plots provide an important tool for assessing mixing of a chain."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ps = dlt_reg.get_posterior_samples(relabel=True, permute=False)\n",
    "ps.keys()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oRu13TIRjRy",
    "outputId": "c1c91198-745c-438f-d64c-a8af3ee4f7eb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "az.plot_trace(\n",
    "    ps,\n",
    "    var_names=['trend.unemploy', 'trend.job', 'sp500', 'vix', 'obs_sigma'],\n",
    "    chain_prop={\"color\": ['r', 'b', 'g', 'y']},\n",
    "    figsize=(10, 8),\n",
    ");"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "id": "DkqoWjDnRgQb",
    "outputId": "b0e92412-e9ba-443a-f829-2378273e8d86"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1oBUrWZ_UVP"
   },
   "source": [
    "### Pair density plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrAUW5oM_isJ"
   },
   "source": [
    "We can also check the density of samples by pair plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zH4wRZyh-kn-",
    "outputId": "4197fcb6-8548-403b-d30a-159110268e25"
   },
   "outputs": [],
   "source": [
    "# az.plot_pair(\n",
    "#     ps,\n",
    "#     var_names=['trend.unemploy', 'trend.job', 'sp500', 'vix', 'obs_sigma'],\n",
    "#     kind=[\"scatter\", \"kde\"],\n",
    "#     marginals=True,\n",
    "#     point_estimate=\"median\",\n",
    "#     textsize=10.5,\n",
    "#     figsize=(8,8)\n",
    "# );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYj-smh5QNEu"
   },
   "source": [
    "# Regression with Informative Priors / Regularized Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNzRoGhwQ_Ub"
   },
   "source": [
    "Due to various reasons, users may obtain further knowledge on some of the regressors or they want to propose different regularization on different regressors. These informative priors basically means to replace the defaults ($\\mu$, $\\sigma$) mentioned previously. In orbit, this process is done via the arguments `regressor_beta_prior` and `regressor_sigma_prior`. These two lists should be of the same length as `regressor_col`."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition, we can set a *sign* constraint for each coefficient $\\beta_j$.  This is can be done by supplying the `regressor_sign` as a list where elements are in one of followings:\n",
    "\n",
    "* '=': $\\beta_j ~\\sim \\mathcal{N}(0, \\sigma_j^2)$  i.e. $\\beta_j \\in (-\\inf, \\inf)$\n",
    "* '+': $\\beta_j ~\\sim \\mathcal{N}^+(0, \\sigma_j^2)$  i.e. $\\beta_j \\in [0, \\inf)$\n",
    "* '-': $\\beta_j ~\\sim \\mathcal{N}^-(0, \\sigma_j^2)$  i.e. $\\beta_j \\in (-\\inf, 0]$\n",
    "\n",
    "Based on intuition, it's reasonable to assume search terms such as \"unemployment\", \"filling\" and **VIX** index to be positively correlated (`+` sign is used in this case) and upward shock of **SP500** (`-` sign) to be negatively correlated to the outcome. Otherwise, an unbounded coefficient can be used (`=` sign).\n",
    "\n",
    "Furthermore, regressors such as seach queries may have more direct impact than stock marker indices.  Hence, a smaller $\\sigma$ is considered."
   ],
   "metadata": {
    "id": "vHtp-HO2-VBZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JcDeRsAQK5K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ece9e512-fd58-40f9-902a-508df5d5867a"
   },
   "outputs": [],
   "source": [
    "dlt_reg_adjust = DLT(\n",
    "    response_col=response_col,\n",
    "    date_col=date_col,\n",
    "    regressor_col=['trend.unemploy', 'trend.job', 'sp500','vix'],\n",
    "    regressor_sign=['+','=','-','+'],\n",
    "    regressor_sigma_prior=[0.3, 0.1, 0.05, 0.1],\n",
    "    num_warmup=4000,\n",
    "    num_sample=1000,\n",
    "    estimator='stan-mcmc',\n",
    "    seed=2022,\n",
    ")\n",
    "dlt_reg_adjust.fit(df=train_df)\n",
    "predicted_df_reg_adjust = dlt_reg_adjust.predict(test_df, decompose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "cCKbbDQaydlZ",
    "outputId": "ffeaaa42-7444-4530-e523-1af9c5109068"
   },
   "outputs": [],
   "source": [
    "_ = plot_predicted_data(training_actual_df=train_df, predicted_df=predicted_df_reg_adjust, \n",
    "                        date_col=date_col, actual_col=response_col, test_actual_df=test_df,\n",
    "                        use_orbit_style=False,\n",
    "                        title='DLT with Regresion of Informative Priors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "2Kx3u5vqRZmY",
    "outputId": "6452530f-843b-40a3-f954-db87b9daf8dd"
   },
   "outputs": [],
   "source": [
    "dlt_reg_adjust.get_regression_coefs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqkWZzEURbQd",
    "outputId": "e9cb73a1-4848-4ab8-de95-f73b05d15b83"
   },
   "outputs": [],
   "source": [
    "naive_mae = mae(predicted_df['prediction'].values, test_df['claims'].values)\n",
    "reg_mae = mae(predicted_df_reg['prediction'].values, test_df['claims'].values)\n",
    "reg_adjust_mae = mae(predicted_df_reg_adjust['prediction'].values, test_df['claims'].values)\n",
    "\n",
    "print(\"----------------Mean Absolute Error Summary----------------\")\n",
    "print(\"Naive Model: {:.3f}\\nRegression Model: {:.3f}\\nRefined Regression Model: {:.3f}\".format(\n",
    "    naive_mae, reg_mae, reg_adjust_mae\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "This demo showcases a use case in nowcasting. Although this may not be applicable in real-time forecasting, it mainly introduces the regression analysis with time-series modeling in `Orbit`. For people who have concerns on the forecastability, one can consider introducing lag on regressors.\n",
    "\n",
    "Also, `Orbit` allows informative priors where sometime can be useful in combining multiple source of insights together."
   ],
   "metadata": {
    "id": "1WkGNgIuZ-C5"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
