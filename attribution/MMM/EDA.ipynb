{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import xgboost as xgb\n",
    "# from xgboost import XGBRegressor\n",
    "from fitter import Fitter\n",
    "# from scipy import signal\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pmdarima.arima import ADFTest\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import KNNImputer\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import linear_model\n",
    "sns.set_style('darkgrid')\n",
    "# import arviz as az\n",
    "# import pymc3 as pm\n",
    "# from theano import tensor as tt\n",
    "# from fitter import Fitter, get_common_distributions, get_distributions\n",
    "# import mean_squared_error\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# from statsmodels.tools.tools import add_constant\n",
    "# from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "# from pandas.plotting import lag_plot\n",
    "# from pmdarima.arima import auto_arima\n",
    "%matplotlib inline\n",
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.chdir('G:/My Drive/To_Do/MMM/Raw_Hain_Data/Pivot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# smd_pivot = pd.read_csv('smd_pivot.csv')\n",
    "# ts_pivot = pd.read_csv('ts_pivot.csv')\n",
    "# ct = pd.read_csv('ct_spend.csv') # need information on revenue or impressions\n",
    "dm_pivot = pd.read_csv('dm_pivot_2.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This summary of different stats for the original model can be compared to the .describe()\n",
    "of the imputed dataset to see how it changed (or didn't change)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = dm_pivot\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def missing_values(df):\n",
    "    names = [var for var in df.columns]\n",
    "    missing_count = df[names].isnull().sum()\n",
    "    var_count = np.array(df[names].isnull().sum() * 100/ len(df)).round(2)\n",
    "    missing = pd.DataFrame(index=names)\n",
    "    missing[\"Count Missing\"] = missing_count\n",
    "    missing[\"Percent Missing\"] = var_count\n",
    "    print(missing)\n",
    "\n",
    "\n",
    "def dickey_fuller(df):\n",
    "    adf_test = ADFTest(alpha = .05)\n",
    "    print('A value of True means that the ADFTest null hypothesis that the time series is non-stationary is correct.')\n",
    "    result = adf_test.should_diff(df['revenue'])\n",
    "    return result\n",
    "\n",
    "\n",
    "def unique(df):\n",
    "    percent_unique = np.array(100 * df.nunique()/len(df.index)).round(2)\n",
    "    count_unique = df.nunique()\n",
    "    names = [var for var in df.columns]\n",
    "    unique_df = pd.DataFrame(index=names)\n",
    "    unique_df[\"Count Unique\"] = count_unique\n",
    "    unique_df[\"Percent Unique\"] = percent_unique\n",
    "    print(unique_df)\n",
    "\n",
    "\n",
    "def corr_plot(df):\n",
    "    corr_temp = df.drop(['DATE'], axis=1)\n",
    "    corr_names = corr_temp.columns.tolist()\n",
    "    temp_df = df[corr_names]\n",
    "    corr = temp_df.corr(method=\"pearson\").round(2)\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    f, ax = plt.subplots(figsize=(18, 18))\n",
    "    cmap = sns.diverging_palette(250, 1, as_cmap=True)\n",
    "    sns.heatmap(corr, annot=True, mask=mask, cmap=cmap,\n",
    "                vmax=1, vmin=-1, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "\n",
    "def summary(df):\n",
    "    print(missing_values(df))\n",
    "    print(unique(df))\n",
    "    corr_plot(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This summary gives us information on missing values, the number of unique values, and correlation before imputation.\n",
    "In some cases, it suggests that columns of entirely missing data might be dropped right away. Once again, it is valuable\n",
    "to compare to the imputed result."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helps drop variables when necessary and creates a few variables that will be used later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df = df.drop([], axis=1)\n",
    "temp_week = df['DATE']\n",
    "corr_temp = df.drop(['DATE'], axis=1)\n",
    "corr_names = corr_temp.columns.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The KNNImputer uses a method similar to regression and nearby non-missing values to fill in missing values.\n",
    "The number of neighboring values can be adjusted to find better fits for the missing values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # KNN Imputation\n",
    "# df_knn = temp_df.filter([], axis=1).copy()\n",
    "# # Define scaler to set values between 0 and 1\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# df_knn = pd.DataFrame(scaler.fit_transform(df_knn), columns = df_knn.columns)\n",
    "# # Define KNN imputer and fill missing values\n",
    "# knn_imputer = KNNImputer(n_neighbors=12, weights='distance', metric='nan_euclidean')\n",
    "# df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df_knn), columns=df_knn.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns='DATE')\n",
    "imputer = KNNImputer(n_neighbors=10, weights='distance', metric='nan_euclidean')\n",
    "imputed_KNN = imputer.fit_transform(df)\n",
    "imputed_KNN = pd.DataFrame(imputed_KNN, columns = df.columns)\n",
    "KNN_imputation = pd.concat([imputed_KNN, temp_week], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multiple Imputation by Chained Equations (MICE) uses iterations of Bayesian Ridge Linear models\n",
    "and takes the averages of their results to determine the imputed values. Compared to most other methods,\n",
    "it performs better with extremely sparse data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mice_names = tuple(corr_names)\n",
    "mice_temp = df[corr_names]\n",
    "df_mice = mice_temp.filter(mice_names, axis=1).copy()\n",
    "\n",
    "mice_estimator = IterativeImputer(estimator=linear_model.BayesianRidge(), sample_posterior=True, max_iter=40,\n",
    "                                n_nearest_features=10, imputation_order='random', min_value=500)\n",
    "df_mice_imputed = pd.DataFrame(mice_estimator.fit_transform(df_mice), columns=df_mice.columns)\n",
    "imputed_mice = pd.concat([df_mice_imputed, temp_week], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# imputed_mice.to_csv('smd_mice_1.csv', encoding='utf-8', index=False)\n",
    "# KNN_imputation.to_csv('smd_KNN_1.csv', encoding='utf-8', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Post Hoc Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Augmented Dickey-Fuller function tests if a time series needs differencing,\n",
    "which returns True, or if the time series is stationary. It also implies that\n",
    "if the test returns True, it is not a random walk and the imputation is somewhat\n",
    "decent, at the minimum."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = imputed_mice"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dickey_fuller(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Autocorrelation is another test for time series that tests if the current date's value is correlated\n",
    "with previous observations. If the blue line is above the dotted line, this suggests the time series\n",
    "is autocorrelated as well as the time series not being random."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.figsize':(10,4), 'figure.dpi':120})\n",
    "autocorrelation_plot(df['revenue'].tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following tests plot the distribution of the variables in the imputed dataset,\n",
    "as well as give you the most likely distribution of its parameters. This can be useful\n",
    "for testing if the distribution is known or comparing against a similar variable whose\n",
    "distribution as known. It could also be used in creating synthetic data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_df = df.drop(['DATE'], axis=1)\n",
    "dist_list = ['gamma', 'expon', 'cauchy', 'norm', 'uniform']\n",
    "\n",
    "for var in temp_df:\n",
    "    dist_test = temp_df[var].dropna()\n",
    "    dist_test = dist_test.values\n",
    "    f = Fitter(dist_test, distributions=dist_list, timeout=60)\n",
    "    f.fit()\n",
    "    print(var)\n",
    "    print(f.summary(plot=False))\n",
    "    print(f.get_best(method='sumsquare_error'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(9, 1, figsize=(23, 14))\n",
    "sns.kdeplot(ax=axes[0], x='onlinedisplay_S', data=df)\n",
    "sns.kdeplot(ax=axes[1], x='onlinedisplay_I', data=df)\n",
    "sns.kdeplot(ax=axes[2], x='onlinevideo_S', data=df)\n",
    "sns.kdeplot(ax=axes[3], x='onlinevideo_I', data=df)\n",
    "sns.kdeplot(ax=axes[4], x='paidsearch_S', data=df)\n",
    "sns.kdeplot(ax=axes[5], x='paidsearch_I', data=df)\n",
    "sns.kdeplot(ax=axes[6], x='social_S', data=df)\n",
    "sns.kdeplot(ax=axes[7], x='social_I', data=df)\n",
    "sns.kdeplot(ax=axes[8], x='revenue', data=df)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
