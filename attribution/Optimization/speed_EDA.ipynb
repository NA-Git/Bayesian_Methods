{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### The purpose of this EDA notebook is the following:\n",
    "- Better understand the nature of the relationship between the independent variables\n",
    "- Create an initial model with reasonable economic assumptions that may be dropped in later versions\n",
    "- Explore methods of imputation for missing variables to provide more data samples\n",
    "- Avoid linear combinations that might be more difficult to spot in the Bayesian Modeling process\n",
    "- Establish a reasonable measure of variable importance, which along with correlation plots may inform initial hierarchies\n",
    "- Create visualizations of poor quality data and also establish probability distributions for the likelihood function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Import data and necessary packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ['KERAS_BACKEND'] = 'theano'\n",
    "# os.environ['THEANO_FLAGS']='cpu'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import arviz as az\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# import category_encoders as ce\n",
    "# import shap\n",
    "import mkl\n",
    "import xarray\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "\n",
    "# %load_ext timeit\n",
    "# %load_ext heat\n",
    "# %load_ext line_profiler\n",
    "# %load_ext memory_profiler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/norri/Desktop/cortex_Push_2.csv')\n",
    "df_bu = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(['Program Name', 'Retailers', 'Tactic', 'Vendor', 'Tactic Start Date',\n",
    "              'Tactic End Date'], axis=1)\n",
    "segment = [var for var in df.columns if df[var].dtype == 'O']\n",
    "df_cat = df.select_dtypes(include=object)\n",
    "# print(df_cat.nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.RMN.replace(('Yes', 'No'), (1, 0), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for col in df.select_dtypes(include='object'):\n",
    "#     if df[col].nunique() <= 25:\n",
    "#         sns.countplot(y=col, data=df)\n",
    "#         plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df = df.drop(\n",
    "#     [], axis=1)\n",
    "integer = [var for var in df.columns if df[var].dtype == 'int64']\n",
    "df_int = df.select_dtypes(include=int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "        ['Base $', 'Incr $', 'Base Units', 'Incr Units',\n",
    "         '$ Shr - Ty Subcategory', 'Units Shr - Ty Category',\n",
    "         'Units Shr - Ty Subcategory'], axis=1)\n",
    "fp = [var for var in df.columns if df[var].dtype == 'float64']\n",
    "fp_na = df[fp].isnull().sum() / len(df) * 100\n",
    "fp_zero = df[fp].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "        ['ClientId', 'Program Id', 'TacticId', 'CategoryId',\n",
    "         'BrandId', 'Nielsen_Week_Year', 'VendorId'], axis=1)\n",
    "df_num = df.select_dtypes(exclude='object')\n",
    "# df_num.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_vars_cat = ['Number of UPCs Selling', 'Any Promo Units', '%ACV Distribution',\n",
    "                  'Feat w/o Disp %ACV', 'Price Decr Only %ACV', 'Disp w/o Feat %ACV',\n",
    "                  'Total Sales', 'Feat & Disp %ACV', 'RMN', 'Tactic Category', 'Brand']\n",
    "\n",
    "final_vars = ['Number of UPCs Selling', 'Any Promo Units', '%ACV Distribution',\n",
    "              'Feat w/o Disp %ACV', 'Price Decr Only %ACV', 'Disp w/o Feat %ACV',\n",
    "              'Total Sales', 'Feat & Disp %ACV', 'RMN']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_final = df[final_vars]\n",
    "\n",
    "dist_list = ['gamma', 'expon', 'cauchy', 'norm', 'uniform']\n",
    "\n",
    "for var in final_vars:\n",
    "    dist_test = df_final[var].dropna()\n",
    "    dist_test = dist_test.values\n",
    "    f = Fitter(dist_test, distributions=dist_list, timeout=60)\n",
    "    f.fit()\n",
    "    print(var)\n",
    "    print(f.summary(plot=False))\n",
    "    print(f.get_best(method='sumsquare_error'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_final_cat = df_bu[final_vars_cat]\n",
    "df_final_cat = df_final_cat[df_final_cat['Total Sales'] > 0.0]\n",
    "\n",
    "print('Original number of obs and Tactic Categories')\n",
    "print(df['Tactic Category'].count())\n",
    "print(df['Tactic Category'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Number of obs, new tactics, and new displays')\n",
    "print(df_final_cat['Tactic Category'].count())\n",
    "print(df_final_cat['Tactic Category'].nunique())\n",
    "print(df_final_cat['Brand'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tt.config.floatX = 'float32'\n",
    "\n",
    "df_final_cat = df_bu[final_vars_cat]\n",
    "df_final_cat = df_final_cat[df_final_cat['Total Sales'] > 0.0]\n",
    "\n",
    "df_final_cat['Total Sales'] = np.log(df_final_cat['Total Sales'])\n",
    "\n",
    "price_decr_idxs, price_decr = pd.factorize(df_final_cat['Price Decr Only %ACV'],\n",
    "                                           sort=True)\n",
    "tactic_idxs, tactics = pd.factorize(df_final_cat['Tactic Category'], sort=True)\n",
    "brand_idxs, brand = pd.factorize(df_final_cat['Brand'], sort=True)\n",
    "coords = {\"tactics\": tactics, 'brand': brand, 'obs_idx': np.arange(len(tactic_idxs)), 'price_decrease': price_decr}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Hierarchical Model with diagnostics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "with pm.Model(coords=coords) as h_model:\n",
    "    tactic_idx = pm.Data(\"Tactic Category\", tactic_idxs, dims=\"obs_idx\")\n",
    "    brand_idx = pm.Data(\"Brand\", brand_idxs, dims=\"obs_idx\")\n",
    "    price_decr = pm.Data(\"Price Decrease Only\", price_decr_idxs, dims=\"obs_idx\")\n",
    "\n",
    "    # Tactic Category hyperpriors parameters:\n",
    "    hp_b_0 = pm.Normal(\"hp_b_0\", mu=0.0, sigma=5.0)\n",
    "    sigma_a = pm.Exponential(\"sigma_a\", 1.0)\n",
    "    hp_b_1 = pm.Normal(\"hp_b_1\", mu=0.0, sigma=1.0)\n",
    "    sigma_b = pm.Exponential(\"sigma_b\", 0.5)\n",
    "\n",
    "    # Brand hyperpriors parameters\n",
    "    hp_b_2 = pm.Normal(\"hp_b_2\", mu=0.0, sigma=5.0)\n",
    "    sigma_c = pm.Exponential(\"sigma_c\", 1.0)\n",
    "    hp_b_3 = pm.Normal(\"hp_b_3\", mu=0.0, sigma=1.0)\n",
    "    sigma_d = pm.Exponential(\"sigma_d\", 0.5)\n",
    "\n",
    "    hp_b_4 = pm.Normal(\"hp_b_4\", mu=0.5, sigma=.3)\n",
    "\n",
    "    # estimates of independent intercepts and interactions of intercepts\n",
    "    b_0 = pm.Normal(\"tactic_int\", mu=hp_b_0, sigma=sigma_a, dims=\"tactics\")\n",
    "    b_1 = pm.Normal(\"tactic_slope\", mu=hp_b_1, sigma=sigma_b, dims=\"tactics\")\n",
    "\n",
    "    b_2 = pm.Normal(\"display_int\", mu=hp_b_2, sigma=sigma_c, dims=\"brand\")\n",
    "    b_3 = pm.Normal(\"display_slope\", mu=hp_b_3, sigma=sigma_d, dims=\"brand\")\n",
    "\n",
    "    price_decr_est = hp_b_4 * price_decr\n",
    "\n",
    "    # estimate of total sales using intercepts\n",
    "    sales_est_1 = b_0[tactic_idx] + b_1[tactic_idx] * brand_idx\n",
    "    sales_est_2 = b_2[brand_idx] + b_3[brand_idx] * tactic_idx\n",
    "    sales_est = sales_est_1 + sales_est_2 + price_decr_est\n",
    "\n",
    "    # Data likelihood\n",
    "    epsilon = pm.Exponential(\"noise\", 1.0)\n",
    "    Total_Sales = pm.Normal(\n",
    "            \"Log_Total_Sales\", mu=sales_est, sigma=epsilon,\n",
    "            observed=df_final_cat['Total Sales'], dims=\"obs_idx\")\n",
    "\n",
    "with h_model:\n",
    "    h_trace = pm.sample(draws=1500, init='advi+adapt_diag',\n",
    "                        tune=1500,\n",
    "                        target_accept=0.995, return_inferencedata=True, max_treedepth=15 )\n",
    "\n",
    "# with h_model:\n",
    "#     trace_ppc = pm.sample_posterior_predictive(h_trace, random_seed=0)\n",
    "#     model_pred = trace_ppc['Log_Total_Sales']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def score_model(trace, y, model_name):\n",
    "    \"\"\"\n",
    "\n",
    "    :param trace: model_trace\n",
    "    :param y: dependent data column\n",
    "    :param model_name: model itself\n",
    "    \"\"\"\n",
    "    ppc = pm.sample_posterior_predictive(trace, samples=20841,\n",
    "                                             model=model_name)\n",
    "    pred = ppc['Log_Total_Sales'].mean(axis=0)\n",
    "    mse = np.sqrt(mean_squared_error(y, pred))\n",
    "    print('The Mean Squared Error')\n",
    "    print(mse)\n",
    "\n",
    "score_model(h_trace, df_final_cat['Total Sales'], h_model)\n",
    "\n",
    "print('Trace Summary and Effective Sample Size')\n",
    "print(az.summary(h_trace, kind='stats'))\n",
    "print(az.summary(h_trace, kind='diagnostics'))\n",
    "az.plot_posterior(h_trace, hdi_prob=0.99)\n",
    "az.plot_energy(h_trace)\n",
    "plt.show()\n",
    "print('Bayesian fraction of missing information')\n",
    "print(az.bfmi(h_trace))\n",
    "az.plot_forest(h_trace, kind='ridgeplot')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with h_model:\n",
    "    trace_ppc = pm.sample_posterior_predictive(h_trace, random_seed=0)\n",
    "    model_pred = trace_ppc['Log_Total_Sales']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(h_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "name": "pycharm-2660a024",
   "language": "python",
   "display_name": "PyCharm (mercury-ds)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}