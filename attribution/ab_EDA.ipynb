{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### The purpose of this EDA notebook is the following:\n",
    "- Better understand the nature of the relationship between the independent variables\n",
    "- Create an initial model with reasonable economic assumptions that may be dropped in later versions\n",
    "- Explore methods of imputation for missing variables to provide more data samples\n",
    "- Avoid linear combinations that might be more difficult to spot in the Bayesian Modeling process\n",
    "- Establish a reasonable measure of variable importance, which along with correlation plots may inform initial hierarchies\n",
    "- Create visualizations of poor quality data and also establish probability distributions for the likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from rfpimp import *\n",
    "from rfpimp import plot_corr_heatmap\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "import category_encoders as ce"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### In an effort to generalize for future EDA, 'df' makes it easier to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4393 entries, 0 to 4392\n",
      "Columns: 123 entries, % Dollar Sales by Merch Any Display to Weighted Average Base Price Per Unit\n",
      "dtypes: float64(107), int64(6), object(10)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/norri/Desktop/all_ab_data.csv')\n",
    "df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The info function above tells us we have three data types and counts of each. The next section will explore those variables in groups."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['Brand Family Value', 'Brand Value', 'Category Value', 'Geography', 'Product', 'Segment Value', 'Time', 'Type Value']\n",
      "Brand Family Value    0.208969\n",
      "Brand Value           0.529706\n",
      "Category Value        0.016390\n",
      "Geography             0.000000\n",
      "Product               0.000000\n",
      "Segment Value         0.140451\n",
      "Time                  0.000000\n",
      "Type Value            0.298657\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4393 entries, 0 to 4392\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Brand Family Value  3475 non-null   object\n",
      " 1   Brand Value         2066 non-null   object\n",
      " 2   Category Value      4321 non-null   object\n",
      " 3   Geography           4393 non-null   object\n",
      " 4   Product             4393 non-null   object\n",
      " 5   Segment Value       3776 non-null   object\n",
      " 6   Time                4393 non-null   object\n",
      " 7   Type Value          3081 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 274.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Brand Family Value Brand Value Category Value  \\\ncount                    3475        2066           4321   \nunique                     41          31              3   \ntop     MICHELOB ULTRA FAMILY   BUD LIGHT           BEER   \nfreq                      332          90           4248   \n\n                   Geography    Product Segment Value                  Time  \\\ncount                   4393       4393          3776                  4393   \nunique                    15         72             6                     6   \ntop     AWG Corp-SRMA - Food  BUD LIGHT  CRAFT/IMPORT  Week Ending 01-02-22   \nfreq                     359         90           969                   740   \n\n       Type Value  \ncount        3081  \nunique          8  \ntop         LIGHT  \nfreq          928  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Brand Family Value</th>\n      <th>Brand Value</th>\n      <th>Category Value</th>\n      <th>Geography</th>\n      <th>Product</th>\n      <th>Segment Value</th>\n      <th>Time</th>\n      <th>Type Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3475</td>\n      <td>2066</td>\n      <td>4321</td>\n      <td>4393</td>\n      <td>4393</td>\n      <td>3776</td>\n      <td>4393</td>\n      <td>3081</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>41</td>\n      <td>31</td>\n      <td>3</td>\n      <td>15</td>\n      <td>72</td>\n      <td>6</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>MICHELOB ULTRA FAMILY</td>\n      <td>BUD LIGHT</td>\n      <td>BEER</td>\n      <td>AWG Corp-SRMA - Food</td>\n      <td>BUD LIGHT</td>\n      <td>CRAFT/IMPORT</td>\n      <td>Week Ending 01-02-22</td>\n      <td>LIGHT</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>332</td>\n      <td>90</td>\n      <td>4248</td>\n      <td>359</td>\n      <td>90</td>\n      <td>969</td>\n      <td>740</td>\n      <td>928</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['CONCAT', 'Brewer Value'], axis=1)\n",
    "segment = [var for var in df.columns if df[var].dtype == 'O']\n",
    "print('There are {} categorical variables\\n'.format(len(segment)))\n",
    "print('The categorical variables are :\\n\\n', segment)\n",
    "print(df[segment].isnull().sum() / len(df))\n",
    "df_cat = df.select_dtypes(include=object)\n",
    "df_cat.info()\n",
    "df_cat.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 integer variables\n",
      "\n",
      "The integer variables are :\n",
      "\n",
      " []\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(\n",
    "    ['F81', 'Product Development Index', 'Sum of Dollar Sales Checkout Display',\n",
    "     'Sum of Dollar Sales Outside Display', 'Sum of Dollar Sales Signage and Feature',\n",
    "     'Sum of Dollar Sales Signage, Feature and Display'], axis=1)\n",
    "integer = [var for var in df.columns if df[var].dtype == 'int64']\n",
    "print('There are {} integer variables\\n'.format(len(integer)))\n",
    "print('The integer variables are :\\n\\n', integer)\n",
    "print(df[integer].isnull().sum())\n",
    "df_int = df.select_dtypes(include=int)\n",
    "if len(df_int.columns) > 0.0:\n",
    "    df_int.info()\n",
    "    df_int.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 93 float variables\n",
      "\n",
      "The float variables are :\n",
      "\n",
      " ['% Dollar Sales by Merch Any Display', '% Dollar Sales by Merch Any Feature', '% Dollar Sales by Merch Any Merch', '% Dollar Sales by Merch Any Price Reduction', '% Increase in Dollars by Merch Advertised Frequent Shopper', '% Increase in Dollars by Merch Any Display', '% Increase in Dollars by Merch Any Feature', '% Increase in Dollars by Merch Any Merch', '% Increase in Dollars by Merch Any Price Reduction', '% Increase in Dollars by Merch Display Only', '% Increase in Dollars by Merch Feature and Display', '% Increase in Dollars by Merch Feature and/or Display', '% Increase in Dollars by Merch Feature Only', '% Increase in Dollars by Merch Price Reductions Only', '% Increase in Units by Merch Advertised Frequent Shopper', '% Increase in Units by Merch Any Display', '% Increase in Units by Merch Any Feature', '% Increase in Units by Merch Any Merch', '% Increase in Units by Merch Any Price Reduction', '% Increase in Units by Merch Display Only', '% Increase in Units by Merch Feature and Display', '% Increase in Units by Merch Feature and/or Display', '% Increase in Units by Merch Feature Only', '% Increase in Units by Merch Price Reductions Only', '% Incremental Units by Merch Advertised Frequent Shopper', '% Incremental Units by Merch Any Display', '% Incremental Units by Merch Any Feature', '% Incremental Units by Merch Any Merch', '% Incremental Units by Merch Any Price Reduction', '% Incremental Units by Merch Display Only', '% Incremental Units by Merch Feature and Display', '% Incremental Units by Merch Feature and/or Display', '% Incremental Units by Merch Feature Only', '% Incremental Units by Merch Price Reductions Only', 'ACV Weighted Distribution Any Display', 'Average Weekly ACV Distribution', 'Average Weekly ACV Distribution Any Display', 'Average Weekly ACV Distribution Any Feature', 'Average Weekly ACV Distribution Any Merch', 'Average Weekly ACV Distribution Any Price Reduction', 'Average Weekly ACV Distribution Display Only', 'Average Weekly ACV Distribution Feature and Display', 'Average Weekly ACV Distribution Feature and/or Display', 'Average Weekly ACV Distribution Feature Only', 'Average Weekly ACV Distribution Price Reductions Only', 'Avg Weekly Items per Store Selling', 'Avg Weekly Units per Store Selling', 'Base Dollar Sales', 'Base Dollar Sales % Change vs YA', 'Base Unit Sales', 'Base Unit Sales % Change vs YA', 'Dollar Sales', 'Dollar Sales % Change vs YA', 'Dollar Sales per Pt of Distribution', 'Dollar Sales per Pt of Distribution % Change vs YA', 'Dollar Sales per Pt of Distribution Year Ago', 'Dollar Share of Category', 'Number of Stores Selling', 'Price per Unit', 'Sum of Base Dollar Sales', 'Sum of Dollar Sales', 'Sum of Dollar Sales Advertised Frequent Shopper', 'Sum of Dollar Sales Any Display', 'Sum of Dollar Sales Any Feature', 'Sum of Dollar Sales Any Merch', 'Sum of Dollar Sales Any Price Reduction', 'Sum of Dollar Sales Any Signage', 'Sum of Dollar Sales Banner Sign', 'Sum of Dollar Sales Display Only', 'Sum of Dollar Sales Display with Price', 'Sum of Dollar Sales Display without Price Signage', 'Sum of Dollar Sales Feature and Display', 'Sum of Dollar Sales Feature and/or Display', 'Sum of Dollar Sales Feature Only', 'Sum of Dollar Sales Inside Display', 'Sum of Dollar Sales Lobby Display', 'Sum of Dollar Sales No Merch (non-promo)', 'Sum of Dollar Sales Outdoor Sign', 'Sum of Dollar Sales Price Reductions Only', 'Sum of Dollar Sales Signage and Display', 'Sum of Dollar Sales Signage, Feature or Display', 'Sum of Dollar Sales Window Sign', 'Sum of Incremental Dollars', 'Total Points of Distribution', 'Unit Sales', 'Unit Sales % Change vs YA', 'Unit Sales per Pt of Distribution', 'Unit Share of Category', 'Unit Share of Category Change vs YA', 'Units per Store Selling', 'Units per Store Selling % Change vs YA', 'Units per Store Selling Year Ago', 'Weighted Average Base Price Per Unit']\n",
      "Base Dollar Sales % Change vs YA                10.83542\n",
      "Base Unit Sales % Change vs YA                  10.83542\n",
      "Dollar Sales % Change vs YA                     10.83542\n",
      "Dollar Sales per Pt of Distribution Year Ago    10.83542\n",
      "Unit Sales % Change vs YA                       10.83542\n",
      "Units per Store Selling Year Ago                10.83542\n",
      "dtype: float64\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(\n",
    "    ['Unit Share of SubCategory', 'Dollar Share of SubCategory',\n",
    "     'Incremental Dollars', 'Incremental Dollars % Change vs YA',\n",
    "     'Incremental Units', 'Incremental Units % Change vs YA',\n",
    "     '% Increase in Dollars by Merch Any Special Pack',\n",
    "     '% Increase in Dollars by Merch Special Pack Only',\n",
    "     '% Increase in Units by Merch',\n",
    "     '% Increase in Units by Merch Any Special Pack',\n",
    "     '% Increase in Units by Merch Special Pack Only',\n",
    "     '% Incremental Units by Merch Any Special Pack',\n",
    "     '% Incremental Units by Merch Special Pack Only',\n",
    "     '% Increase in Units by Merch No Merch'], axis=1)\n",
    "fp = [var for var in df.columns if df[var].dtype == 'float64']\n",
    "print('There are {} float variables\\n'.format(len(fp)))\n",
    "print('The float variables are :\\n\\n', fp)\n",
    "fp_na = df[fp].isnull().sum() / len(df) * 100\n",
    "print(fp_na[fp_na > 10])\n",
    "fp_zero = df[fp].sum()\n",
    "print(fp_zero[fp_zero == 0.0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# agreed upon drops\n",
    "df = df.drop(\n",
    "    ['Dollar Sales', 'Sum of Base Dollar Sales',\n",
    "     'Sum of Incremental Dollars', 'Base Dollar Sales',\n",
    "     'Base Dollar Sales % Change vs YA', 'Base Unit Sales'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       % Dollar Sales by Merch Any Display  \\\ncount                          4393.000000   \nmean                              0.068785   \nstd                               0.147870   \nmin                               0.000000   \n25%                               0.000000   \n50%                               0.000000   \n75%                               0.055210   \nmax                               1.000000   \n\n       % Dollar Sales by Merch Any Feature  % Dollar Sales by Merch Any Merch  \\\ncount                          4393.000000                        4393.000000   \nmean                              0.046816                           0.138043   \nstd                               0.162260                           0.228133   \nmin                               0.000000                           0.000000   \n25%                               0.000000                           0.000000   \n50%                               0.000000                           0.021026   \n75%                               0.000000                           0.167083   \nmax                               1.000000                           1.000000   \n\n       % Dollar Sales by Merch Any Price Reduction  \\\ncount                                  4393.000000   \nmean                                      0.060164   \nstd                                       0.146462   \nmin                                       0.000000   \n25%                                       0.000000   \n50%                                       0.001036   \n75%                                       0.045176   \nmax                                       1.000000   \n\n       % Increase in Dollars by Merch Advertised Frequent Shopper  \\\ncount                                        4393.000000            \nmean                                            0.001455            \nstd                                             0.031127            \nmin                                             0.000000            \n25%                                             0.000000            \n50%                                             0.000000            \n75%                                             0.000000            \nmax                                             1.041233            \n\n       % Increase in Dollars by Merch Any Display  \\\ncount                                 4393.000000   \nmean                                     0.063270   \nstd                                      0.305275   \nmin                                     -0.880920   \n25%                                      0.000000   \n50%                                      0.000000   \n75%                                      0.000000   \nmax                                      3.158592   \n\n       % Increase in Dollars by Merch Any Feature  \\\ncount                                 4393.000000   \nmean                                     0.025865   \nstd                                      0.169769   \nmin                                     -0.778573   \n25%                                      0.000000   \n50%                                      0.000000   \n75%                                      0.000000   \nmax                                      3.290151   \n\n       % Increase in Dollars by Merch Any Merch  \\\ncount                               4393.000000   \nmean                                   0.066125   \nstd                                    0.360176   \nmin                                   -0.951749   \n25%                                   -0.008061   \n50%                                    0.000000   \n75%                                    0.090597   \nmax                                    4.666404   \n\n       % Increase in Dollars by Merch Any Price Reduction  \\\ncount                                        4393.000000    \nmean                                            0.087068    \nstd                                             0.425199    \nmin                                            -0.951749    \n25%                                             0.000000    \n50%                                             0.000000    \n75%                                             0.067896    \nmax                                             8.573740    \n\n       % Increase in Dollars by Merch Display Only  ...  \\\ncount                                  4393.000000  ...   \nmean                                      0.055928  ...   \nstd                                       0.298333  ...   \nmin                                      -0.880920  ...   \n25%                                       0.000000  ...   \n50%                                       0.000000  ...   \n75%                                       0.000000  ...   \nmax                                       4.067986  ...   \n\n       Total Points of Distribution     Unit Sales  Unit Sales % Change vs YA  \\\ncount                   4393.000000    4393.000000                3917.000000   \nmean                     103.461055    2172.335267                   1.528799   \nstd                      183.163335    7636.025807                  28.101594   \nmin                        0.025329       0.178856                  -0.996255   \n25%                        7.290226      35.000000                  -0.448000   \n50%                       37.094045     194.000000                  -0.198113   \n75%                      112.573300     979.000000                  -0.005540   \nmax                     2037.747538  109507.510248                1278.886585   \n\n       Unit Sales per Pt of Distribution  Unit Share of Category  \\\ncount                        4393.000000             4393.000000   \nmean                           39.682057                0.789307   \nstd                           105.168853                2.477898   \nmin                             0.436618                0.000032   \n25%                             3.168485                0.020356   \n50%                             9.208365                0.109133   \n75%                            31.266267                0.372046   \nmax                          1980.829850               34.740099   \n\n       Unit Share of Category Change vs YA  Units per Store Selling  \\\ncount                          4393.000000              4393.000000   \nmean                              0.090372                 8.997648   \nstd                               1.500920                21.363508   \nmin                             -13.473599                 0.171188   \n25%                              -0.039655                 2.000000   \n50%                              -0.001882                 3.157895   \n75%                               0.027209                 6.914634   \nmax                              27.798110               345.449559   \n\n       Units per Store Selling % Change vs YA  \\\ncount                             4393.000000   \nmean                                -0.000511   \nstd                                  0.004789   \nmin                                 -0.008952   \n25%                                 -0.002354   \n50%                                 -0.000910   \n75%                                  0.000089   \nmax                                  0.100000   \n\n       Units per Store Selling Year Ago  Weighted Average Base Price Per Unit  \ncount                       3917.000000                           4393.000000  \nmean                          11.177418                             11.538373  \nstd                           25.671570                              4.474148  \nmin                            0.312438                              1.239082  \n25%                            2.535714                              9.173739  \n50%                            4.000000                             11.886448  \n75%                            8.485380                             14.682571  \nmax                          394.195739                             24.990000  \n\n[8 rows x 87 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>% Dollar Sales by Merch Any Display</th>\n      <th>% Dollar Sales by Merch Any Feature</th>\n      <th>% Dollar Sales by Merch Any Merch</th>\n      <th>% Dollar Sales by Merch Any Price Reduction</th>\n      <th>% Increase in Dollars by Merch Advertised Frequent Shopper</th>\n      <th>% Increase in Dollars by Merch Any Display</th>\n      <th>% Increase in Dollars by Merch Any Feature</th>\n      <th>% Increase in Dollars by Merch Any Merch</th>\n      <th>% Increase in Dollars by Merch Any Price Reduction</th>\n      <th>% Increase in Dollars by Merch Display Only</th>\n      <th>...</th>\n      <th>Total Points of Distribution</th>\n      <th>Unit Sales</th>\n      <th>Unit Sales % Change vs YA</th>\n      <th>Unit Sales per Pt of Distribution</th>\n      <th>Unit Share of Category</th>\n      <th>Unit Share of Category Change vs YA</th>\n      <th>Units per Store Selling</th>\n      <th>Units per Store Selling % Change vs YA</th>\n      <th>Units per Store Selling Year Ago</th>\n      <th>Weighted Average Base Price Per Unit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>...</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>3917.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>4393.000000</td>\n      <td>3917.000000</td>\n      <td>4393.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.068785</td>\n      <td>0.046816</td>\n      <td>0.138043</td>\n      <td>0.060164</td>\n      <td>0.001455</td>\n      <td>0.063270</td>\n      <td>0.025865</td>\n      <td>0.066125</td>\n      <td>0.087068</td>\n      <td>0.055928</td>\n      <td>...</td>\n      <td>103.461055</td>\n      <td>2172.335267</td>\n      <td>1.528799</td>\n      <td>39.682057</td>\n      <td>0.789307</td>\n      <td>0.090372</td>\n      <td>8.997648</td>\n      <td>-0.000511</td>\n      <td>11.177418</td>\n      <td>11.538373</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.147870</td>\n      <td>0.162260</td>\n      <td>0.228133</td>\n      <td>0.146462</td>\n      <td>0.031127</td>\n      <td>0.305275</td>\n      <td>0.169769</td>\n      <td>0.360176</td>\n      <td>0.425199</td>\n      <td>0.298333</td>\n      <td>...</td>\n      <td>183.163335</td>\n      <td>7636.025807</td>\n      <td>28.101594</td>\n      <td>105.168853</td>\n      <td>2.477898</td>\n      <td>1.500920</td>\n      <td>21.363508</td>\n      <td>0.004789</td>\n      <td>25.671570</td>\n      <td>4.474148</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.880920</td>\n      <td>-0.778573</td>\n      <td>-0.951749</td>\n      <td>-0.951749</td>\n      <td>-0.880920</td>\n      <td>...</td>\n      <td>0.025329</td>\n      <td>0.178856</td>\n      <td>-0.996255</td>\n      <td>0.436618</td>\n      <td>0.000032</td>\n      <td>-13.473599</td>\n      <td>0.171188</td>\n      <td>-0.008952</td>\n      <td>0.312438</td>\n      <td>1.239082</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.008061</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>7.290226</td>\n      <td>35.000000</td>\n      <td>-0.448000</td>\n      <td>3.168485</td>\n      <td>0.020356</td>\n      <td>-0.039655</td>\n      <td>2.000000</td>\n      <td>-0.002354</td>\n      <td>2.535714</td>\n      <td>9.173739</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.021026</td>\n      <td>0.001036</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>37.094045</td>\n      <td>194.000000</td>\n      <td>-0.198113</td>\n      <td>9.208365</td>\n      <td>0.109133</td>\n      <td>-0.001882</td>\n      <td>3.157895</td>\n      <td>-0.000910</td>\n      <td>4.000000</td>\n      <td>11.886448</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.055210</td>\n      <td>0.000000</td>\n      <td>0.167083</td>\n      <td>0.045176</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.090597</td>\n      <td>0.067896</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>112.573300</td>\n      <td>979.000000</td>\n      <td>-0.005540</td>\n      <td>31.266267</td>\n      <td>0.372046</td>\n      <td>0.027209</td>\n      <td>6.914634</td>\n      <td>0.000089</td>\n      <td>8.485380</td>\n      <td>14.682571</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.041233</td>\n      <td>3.158592</td>\n      <td>3.290151</td>\n      <td>4.666404</td>\n      <td>8.573740</td>\n      <td>4.067986</td>\n      <td>...</td>\n      <td>2037.747538</td>\n      <td>109507.510248</td>\n      <td>1278.886585</td>\n      <td>1980.829850</td>\n      <td>34.740099</td>\n      <td>27.798110</td>\n      <td>345.449559</td>\n      <td>0.100000</td>\n      <td>394.195739</td>\n      <td>24.990000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 87 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can drop year ago columns\n",
    "df_fp = df.select_dtypes('float')\n",
    "df_num = df_fp\n",
    "df_fp.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clearly the float variables contain all the missing data in the dataset. In\n",
    "### cases like this, dropping the missing values are a trade-off to consider\n",
    "### against dropping an entire column and losing its input into the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this section should come later; for larger datasets takes too long to run\n",
    "# with too little return in information\n",
    "cols = 5\n",
    "rows = 20\n",
    "num_cols = df_num.select_dtypes(exclude='object').columns\n",
    "fig = plt.figure(figsize=(cols * 5, rows * 5))\n",
    "for i, col in enumerate(num_cols):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    sns.histplot(x=df[col], ax=ax)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# these visualizations provide some clue as to how to model the large number\n",
    "# of variables and to examine their relationships\n",
    "corr = df_num.corr(method=\"pearson\")\n",
    "corr.style.background_gradient(cmap=\"coolwarm\").set_precision(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Imputation of missing values is too unreliable to base the rest of the\n",
    "##### model on. Later tests will tell if there is any bias present. This is when\n",
    "##### the most standout variables should be chosen for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this is just another visualization of correlation that I like, I may switch it with others\n",
    "# is nice because it is easier to zoom in for inspection\n",
    "viz = plot_corr_heatmap(df_num, figsize=(20, 20))\n",
    "viz.view()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr_imp = corr[abs(corr['Sum of Dollar Sales']) >.5]\n",
    "corr_imp = corr_imp[['Sum of Dollar Sales']]\n",
    "print(corr_imp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(2, 3, figsize=(15, 15))\n",
    "sns.kdeplot(ax=axes[0, 0], x='Sum of Dollar Sales', data=df_num)\n",
    "sns.kdeplot(ax=axes[0, 1], x='Dollar Share of Category', data=df_num)\n",
    "sns.kdeplot(ax=axes[0, 2], x='Sum of Dollar Sales Any Display', data=df_num)\n",
    "sns.kdeplot(ax=axes[1, 0], x='Sum of Dollar Sales Any Merch', data=df_num)\n",
    "sns.kdeplot(ax=axes[1, 1], x='Sum of Dollar Sales No Merch (non-promo)', data=df_num)\n",
    "sns.kdeplot(ax=axes[1, 2], x='Sum of Dollar Sales Any Price Reduction', data=df_num)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### These kde plots will a primary tool in determining the likelihood\n",
    "### distributions and giving information on the prior"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = ['Sum of Dollar Sales Any Merch', 'Dollar Share of Category',\n",
    "            'Sum of Dollar Sales Any Display',\n",
    "            'Sum of Dollar Sales No Merch (non-promo)',\n",
    "            'Sum of Dollar Sales Any Price Reduction',\n",
    "            'Sum of Dollar Sales Feature and/or Display',\n",
    "            'Dollar Sales per Pt of Distribution',\n",
    "            'Units per Store Selling',\n",
    "            'Avg Weekly Units per Store Selling']\n",
    "target = 'Sum of Dollar Sales'\n",
    "\n",
    "df_all = df_num.dropna().astype(dtype='int32')\n",
    "df_all = df_all[features + [target]]\n",
    "df_train, df_test = train_test_split(df_all, test_size=0.15)\n",
    "\n",
    "X_train, y_train = df_train.drop('Sum of Dollar Sales', axis=1), df_train['Sum of Dollar Sales']\n",
    "X_test, y_test = df_test.drop('Sum of Dollar Sales', axis=1), df_test['Sum of Dollar Sales']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1,\n",
    "                            max_features=1.0,\n",
    "                            min_samples_leaf=10, oob_score=True)\n",
    "rf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_features=1.0, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
    "                       oob_score=True, random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "I = importances(rf, X_test, y_test)\n",
    "plot_importances(I, width=12, vscale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This importance plot from a RandomForestClassifier is one of the key\n",
    "### ways we'll understand which variables are the most important"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### With an array of all the variables, I could make an importance plot\n",
    "#### for everything but the categorical variables, but I would have to change\n",
    "#### the dependent variable each time. Remember that we dropped missing values\n",
    "#### instead of dropping columns, which we could do with a column that did not\n",
    "#### make an impression on the correlation plot or importance plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "I = pd.DataFrame()\n",
    "\n",
    "I['Feature'] = X_train.columns\n",
    "I['Importance'] = rf.feature_importances_\n",
    "I = I.sort_values('Importance', ascending=False)\n",
    "I = I.set_index('Feature')\n",
    "viz = plot_importances(I, width=16, vscale=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Our categorical variables shouldn't be forgotten; just alter the threshold\n",
    "#### down from 250 if the axis titles start to look messy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='object'):\n",
    "    if df[col].nunique() <= 250:\n",
    "        sns.countplot(y=col, data=df)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}